{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-26T16:57:38.821162",
     "start_time": "2017-06-26T16:57:21.940010"
    }
   },
   "source": [
    "# Combine Survey Data\n",
    "2017-06-26 \n",
    "MJ Rose, with scripts from Joe Callingham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-01T10:10:02.844724",
     "start_time": "2017-08-01T10:10:02.496753"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import Javascript\n",
    "import numpy as np\n",
    "import os, glob, subprocess, time, psutil, sys, shutil, fnmatch\n",
    "import pandas as pd\n",
    "from mirpy import miriad \n",
    "# note: mirpy is a python2 module that I futurized\n",
    "# so I could use it in python3\n",
    "\n",
    "\n",
    "# Joe's SED plotting \n",
    "import seds_plot_func\n",
    "from gpscssmodels import *\n",
    "\n",
    "# my own\n",
    "from reduction_funcs import *\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stats\n",
    "from astropy.io import fits\n",
    "import sys\n",
    "import scipy.special as special # For access to the incomplete gamma function.\n",
    "import emcee\n",
    "import triangle \n",
    "import inspect\n",
    "\n",
    "sedfile = 'sed_df.pkl'\n",
    "sed_loc = os.getcwd()+\"/\"+sedfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T14:56:16.233916",
     "start_time": "2017-07-31T14:56:16.002011"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Survey(object):\n",
    "    def __init__(self, name, freq, flux_id, flux_err_coeff, flux_scale):\n",
    "        self.name = name\n",
    "        self.freq = freq\n",
    "        self.flux_id = flux_id\n",
    "        self.flux_err_coeff = flux_err_coeff\n",
    "        self.flux_scale = flux_scale\n",
    "    def flux(self, raw_flux_value):\n",
    "        return(raw_flux_value*self.flux_scale)\n",
    "    def flux_err(self,raw_flux_value):\n",
    "        if not isinstance(self.flux_err_coeff, float):\n",
    "            return(['look in {0} and scale by {1}'.format(self.flux_err_coeff, self.flux_scale),self.flux_err_coeff, self.flux_scale] )\n",
    "        else:\n",
    "            return(raw_flux_value*self.flux_scale*self.flux_err_coeff)\n",
    "\n",
    "        \n",
    "# double check the scalings        \n",
    "surveys = [Survey('VLSSr', 0.074, \"PEAK INT_1\", 0.1, 1), Survey('TGSS', 0.148, \"Total_flux\", 'E_Total_flux', 10**(-3)), \n",
    "           Survey('MRC', 0.408, 'S408', 0.1, 1), Survey('SUMSS', 0.843, \"St\", 0.05, 10**(-3)), \n",
    "           Survey('NVSS', 1.40, \"PEAK INT_2\", 0.05, 1), Survey('ATPMN', 4.85, \"S5_1\", 0.1, 10**(-3)),\n",
    "           Survey('ATPMN', 8.64, 'S8_1', 0.1, 10**(-3)), Survey('AT20G', 19.904001, 'S20', 0.05, 10**(-3)),\n",
    "           Survey('AT20G_8', 8.641001, 'S8_2', 0.05, 10**(-3)),Survey('AT20G_5', 4.8001, 'S5_2', 0.05, 10**(-3))]\n",
    "ATCA_err = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collect data from various files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T14:56:53.780958",
     "start_time": "2017-07-31T14:56:16.240017"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufvmeas data found for 79/127 of your sources\n"
     ]
    }
   ],
   "source": [
    "# path to ATCA reduced data\n",
    "uvfmeas_paths = []\n",
    "for p in [\"/Volumes/mjrose/C3030/\"]:\n",
    "    path = p\n",
    "    regex = 'uvfmeaslog*'\n",
    "    uvfmeas_paths.extend(recursive_glob(path, regex))\n",
    "\n",
    "# path to matched gleam and friends table\n",
    "gleam = \"/Users/mmcintosh/Dropbox/ASTRON2017/C3030/survey_data/gleam_and_friends.csv\" #supermatched.csv\"\n",
    "df = pd.read_csv(gleam, sep=\",\")\n",
    "# get rid of blank rows\n",
    "df = df.dropna(0, 'all')\n",
    "df = df.dropna(subset=['ID'])\n",
    "for i in df.index.tolist():\n",
    "    df.set_value(i,'ID',''.join(df.loc[i]['ID'].split()).lower())\n",
    "    \n",
    "    \n",
    "\n",
    "# get rid of repeated entries\n",
    "for i in df.index.tolist():\n",
    "    # find all rows that have similar IDs\n",
    "    try:\n",
    "        name = df.loc[i].ID\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    possible_IDs = np.unique([name.split('pks')[-1], name.split('mwacsj')[-1], name])\n",
    "    \n",
    "    repeats = []\n",
    "    for t in possible_IDs:\n",
    "        repeats.extend([a for a,b in enumerate(df.ID) if t in b])\n",
    "    \n",
    "    repeats = np.unique(repeats)\n",
    "    \n",
    "    # from the repeated IDs, pick out the longest name to keep\n",
    "    # ID_tokeep = max(df.loc[repeats].ID, key=len)\n",
    "    # set ID to array of possible IDs\n",
    "\n",
    "    # combine repeated rows into one new row\n",
    "    new_entry = pd.concat([df.loc[j].dropna() for j in repeats])\n",
    "    duplicate_entries = new_entry[new_entry.index.duplicated()].index\n",
    "    for entry in duplicate_entries:\n",
    "        dupes = new_entry[entry].values\n",
    "        new_entry = new_entry.drop(entry)\n",
    "        new_entry[entry] = dupes\n",
    "    \n",
    "    \n",
    "    # remove old repeated rows\n",
    "    df = df.drop(df.index[repeats])\n",
    "    \n",
    "    # add in the new combined row\n",
    "    df = df.append(new_entry, ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "# get column names for gleam data\n",
    "colnames = [s for s in list(df) if \"err_int_flux\" in s]\n",
    "#print(colnames)\n",
    "# ok, so all but the first and last\n",
    "colnames = colnames[1:-1]\n",
    "#print(colnames)\n",
    "\n",
    "# new df to write results to \n",
    "sed_df = pd.DataFrame({'name' : df.ID.values, 'freq': '', 'flux':'', 'flux_err':'', 'best_model':''})\n",
    "\n",
    "# for each name, make an array of freq, flux\n",
    "counter = 0 \n",
    "missing_uv = []\n",
    "for i in df.index.tolist():\n",
    "    \n",
    "    # find uvfmeas data \n",
    "    uvfmeas_freq_arr = []\n",
    "    uvfmeas_freq_err_arr = []\n",
    "    uvfmeas_flux_arr = []\n",
    "    uvfmeas_flux_err_arr = []\n",
    "        \n",
    "    name = df.loc[i].ID\n",
    "    if not isinstance(name, str):\n",
    "        name = name[0]\n",
    "    \n",
    "    # check a couple different versions of the name\n",
    "    \n",
    "    try:\n",
    "        path = [s for s in uvfmeas_paths if name in s]\n",
    "        if path == []:\n",
    "            path = [s for s in uvfmeas_paths if name.split('pks')[-1] in s]\n",
    "        if path == []:\n",
    "            path = [s for s in uvfmeas_paths if name.split('mwacsj')[-1] in s]\n",
    "        if path == []:\n",
    "            path = [s for s in uvfmeas_paths if name.split('mwacsj')[-1].split('-')[0] in s]\n",
    "        if path == []:\n",
    "            missing_uv.append(i)\n",
    "            counter +=1\n",
    "            \n",
    "            \n",
    "        \n",
    "        for p in sorted(path):\n",
    "            temp = np.genfromtxt(p)\n",
    "            temp = list(zip(*temp))\n",
    "            temp_freq_arr = temp[0]\n",
    "            temp_flux_arr = temp[1]\n",
    "            temp_flux_err_arr = [f*ATCA_err for f in temp_flux_arr]\n",
    "            temp_freq_err_arr = np.repeat(0, len(temp_freq_arr))\n",
    "            #print(np.max(temp_freq_arr), np.min(temp_freq_arr))\n",
    "\n",
    "            uvfmeas_freq_arr.extend(temp_freq_arr)\n",
    "            uvfmeas_freq_err_arr.extend(temp_freq_err_arr)\n",
    "            uvfmeas_flux_arr.extend(temp_flux_arr)\n",
    "            uvfmeas_flux_err_arr.extend(temp_flux_err_arr)\n",
    "        \n",
    "    except:\n",
    "        print('no ufvmeas data for {0}'.format(name))\n",
    "\n",
    "        \n",
    "        \n",
    "    # find the singular survey points\n",
    "\n",
    "    survey_flux_arr = []\n",
    "    survey_flux_err_arr = []\n",
    "    survey_freq_arr = []\n",
    "    for survey in surveys: \n",
    "        rawflux = df.loc[i][survey.flux_id]\n",
    "        if isinstance(rawflux, np.ndarray):\n",
    "            print('duplicate error with {0}'.format(name))\n",
    "            for j in np.arange(len(rawflux)):\n",
    "                if not np.isnan(rawflux[j]):\n",
    "                    flux = survey.flux(rawflux[j])\n",
    "                    freq = survey.freq\n",
    "                    flux_err = survey.flux_err(rawflux[j])\n",
    "                    if not isinstance(flux_err, float):\n",
    "                        flux_err = df.loc[i][flux_err[1]]*flux_err[2]\n",
    "                    #print(survey.name + \" with freq {1} has a flux of {0}\".format(flux, freq))\n",
    "\n",
    "                    survey_flux_arr.append(flux)\n",
    "                    survey_flux_err_arr.append(flux_err)\n",
    "                    survey_freq_arr.append(freq)    \n",
    "                \n",
    "        else:   \n",
    "            if not np.isnan(rawflux):\n",
    "                flux = survey.flux(rawflux)\n",
    "                freq = survey.freq\n",
    "                flux_err = survey.flux_err(rawflux)\n",
    "                if not isinstance(flux_err, float):\n",
    "                    flux_err = df.loc[i][flux_err[1]]*flux_err[2]\n",
    "                #print(survey.name + \" with freq {1} has a flux of {0}\".format(flux, freq))\n",
    "\n",
    "                survey_flux_arr.append(flux)\n",
    "                survey_flux_err_arr.append(flux_err)\n",
    "                survey_freq_arr.append(freq)    \n",
    "\n",
    "    # find gleam catalog data\n",
    "\n",
    "    gleam_freq_arr = []\n",
    "    gleam_freq_err_arr = []\n",
    "    gleam_flux_err_arr = []\n",
    "    gleam_flux_arr = []\n",
    "\n",
    "\n",
    "    for col in colnames: \n",
    "\n",
    "        # skip over data that is too noisy\n",
    "        flux = df.loc[i][col.split('err_')[-1]]\n",
    "        rms = df.loc[i]['local_rms_'+col.split('_')[-1]]\n",
    "        if isinstance(flux, np.ndarray):\n",
    "            for f in np.arange(len(flux)): \n",
    "                \n",
    "                snr = flux[f]/rms[f]\n",
    "                if snr >= 3.0:\n",
    "\n",
    "                    gleam_freq_arr.append(float(\"0.\"+col.split(\"_\")[-1]))\n",
    "                    #gleam_freq_err_arr.append(0)\n",
    "\n",
    "                    gleam_flux_arr.append(f)\n",
    "\n",
    "                    err = np.sqrt((df.loc[i][col][f])**2 + \\\n",
    "                    (df.loc[i][col.split('err_')[-1]][f]* df.loc[i]['err_abs_flux_pct'][f]*10**(-2) ) **2 )\n",
    "                    gleam_flux_err_arr.append(err) \n",
    "                \n",
    "        else:\n",
    "            snr = flux/rms\n",
    "            if snr >= 3.0:\n",
    "\n",
    "                gleam_freq_arr.append(float(\"0.\"+col.split(\"_\")[-1]))\n",
    "                #gleam_freq_err_arr.append(0)\n",
    "\n",
    "                gleam_flux_arr.append(flux)\n",
    "\n",
    "                err = np.sqrt((df.loc[i][col])**2 + \\\n",
    "                (df.loc[i][col.split('err_')[-1]]* df.loc[i]['err_abs_flux_pct']*10**(-2) ) **2 )\n",
    "                gleam_flux_err_arr.append(err) \n",
    "\n",
    "\n",
    "    # append all\n",
    "\n",
    "    '''freq_arr = np.concatenate([uvfmeas_freq_arr, survey_freq_arr, gleam_freq_arr[::-1]], axis=0)\n",
    "    #freq_err_arr = np.concatenate([uvfmeas_freq_err_arr, gleam_freq_err_arr[::-1]], axis=0)\n",
    "    flux_arr = np.concatenate([uvfmeas_flux_arr, survey_flux_arr, gleam_flux_arr[::-1]],axis=0)\n",
    "    flux_err_arr = np.concatenate([uvfmeas_flux_err_arr, survey_flux_err_arr, gleam_flux_err_arr[::-1]],axis=0)'''\n",
    "\n",
    "\n",
    "    freq_arr = np.concatenate([uvfmeas_freq_arr, survey_freq_arr, gleam_freq_arr], axis=0)\n",
    "    flux_arr = np.concatenate([uvfmeas_flux_arr, survey_flux_arr, gleam_flux_arr],axis=0)\n",
    "    flux_err_arr = np.concatenate([uvfmeas_flux_err_arr, survey_flux_err_arr, gleam_flux_err_arr],axis=0)\n",
    "\n",
    "    # add to df\n",
    "    sed_df.set_value(i, 'flux', flux_arr) \n",
    "    sed_df.set_value(i, 'flux_err', flux_err_arr) \n",
    "    sed_df.set_value(i, 'freq', freq_arr) \n",
    "    #sed_df.set_value(i, 'freq_err', freq_err_arr) \n",
    "\n",
    "    \n",
    "# don't keep matches for sources without ATCA data    \n",
    "#sed_df.drop(sed_df.index[missing_uv], inplace=True)\n",
    "#sed_df.reset_index(drop=True, inplace=True)    \n",
    "    \n",
    "# save df for next time\n",
    "sed_df.to_pickle(sed_loc)\n",
    "    \n",
    "print('ufvmeas data found for {0}/{1} of your sources'.format(len(df) - counter, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-01T10:10:08.069426",
     "start_time": "2017-08-01T10:10:07.567852"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to matched gleam and friends table\n",
    "gleam = \"/Users/mmcintosh/Dropbox/ASTRON2017/C3030/survey_data/gleam_and_friends.csv\" #supermatched.csv\"\n",
    "df = pd.read_csv(gleam, sep=\",\")\n",
    "# get rid of blank rows\n",
    "df = df.dropna(0, 'all')\n",
    "df = df.dropna(subset=['ID'])\n",
    "for i in df.index.tolist():\n",
    "    df.set_value(i,'ID',''.join(df.loc[i]['ID'].split()).lower())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-01T10:10:51.277603",
     "start_time": "2017-08-01T10:10:51.262465"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'background_wide',\n",
       " 'local_rms_wide',\n",
       " 'ra_str',\n",
       " 'dec_str',\n",
       " 'RAJ2000',\n",
       " 'err_RAJ2000',\n",
       " 'DEJ2000',\n",
       " 'err_DEJ2000',\n",
       " 'peak_flux_wide',\n",
       " 'err_peak_flux_wide',\n",
       " 'int_flux_wide',\n",
       " 'err_int_flux_wide',\n",
       " 'a_wide',\n",
       " 'err_a_wide',\n",
       " 'b_wide',\n",
       " 'err_b_wide',\n",
       " 'pa_wide',\n",
       " 'err_pa_wide',\n",
       " 'residual_mean_wide',\n",
       " 'residual_std_wide',\n",
       " 'err_abs_flux_pct',\n",
       " 'err_fit_flux_pct',\n",
       " 'psf_a_wide',\n",
       " 'psf_b_wide',\n",
       " 'psf_pa_wide',\n",
       " 'background_076',\n",
       " 'local_rms_076',\n",
       " 'peak_flux_076',\n",
       " 'err_peak_flux_076',\n",
       " 'int_flux_076',\n",
       " 'err_int_flux_076',\n",
       " 'a_076',\n",
       " 'b_076',\n",
       " 'pa_076',\n",
       " 'residual_mean_076',\n",
       " 'residual_std_076',\n",
       " 'psf_a_076',\n",
       " 'psf_b_076',\n",
       " 'psf_pa_076',\n",
       " 'background_084',\n",
       " 'local_rms_084',\n",
       " 'peak_flux_084',\n",
       " 'err_peak_flux_084',\n",
       " 'int_flux_084',\n",
       " 'err_int_flux_084',\n",
       " 'a_084',\n",
       " 'b_084',\n",
       " 'pa_084',\n",
       " 'residual_mean_084',\n",
       " 'residual_std_084',\n",
       " 'psf_a_084',\n",
       " 'psf_b_084',\n",
       " 'psf_pa_084',\n",
       " 'background_092',\n",
       " 'local_rms_092',\n",
       " 'peak_flux_092',\n",
       " 'err_peak_flux_092',\n",
       " 'int_flux_092',\n",
       " 'err_int_flux_092',\n",
       " 'a_092',\n",
       " 'b_092',\n",
       " 'pa_092',\n",
       " 'residual_mean_092',\n",
       " 'residual_std_092',\n",
       " 'psf_a_092',\n",
       " 'psf_b_092',\n",
       " 'psf_pa_092',\n",
       " 'background_099',\n",
       " 'local_rms_099',\n",
       " 'peak_flux_099',\n",
       " 'err_peak_flux_099',\n",
       " 'int_flux_099',\n",
       " 'err_int_flux_099',\n",
       " 'a_099',\n",
       " 'b_099',\n",
       " 'pa_099',\n",
       " 'residual_mean_099',\n",
       " 'residual_std_099',\n",
       " 'psf_a_099',\n",
       " 'psf_b_099',\n",
       " 'psf_pa_099',\n",
       " 'background_107',\n",
       " 'local_rms_107',\n",
       " 'peak_flux_107',\n",
       " 'err_peak_flux_107',\n",
       " 'int_flux_107',\n",
       " 'err_int_flux_107',\n",
       " 'a_107',\n",
       " 'b_107',\n",
       " 'pa_107',\n",
       " 'residual_mean_107',\n",
       " 'residual_std_107',\n",
       " 'psf_a_107',\n",
       " 'psf_b_107',\n",
       " 'psf_pa_107',\n",
       " 'background_115',\n",
       " 'local_rms_115',\n",
       " 'peak_flux_115',\n",
       " 'err_peak_flux_115',\n",
       " 'int_flux_115',\n",
       " 'err_int_flux_115',\n",
       " 'a_115',\n",
       " 'b_115',\n",
       " 'pa_115',\n",
       " 'residual_mean_115',\n",
       " 'residual_std_115',\n",
       " 'psf_a_115',\n",
       " 'psf_b_115',\n",
       " 'psf_pa_115',\n",
       " 'background_122',\n",
       " 'local_rms_122',\n",
       " 'peak_flux_122',\n",
       " 'err_peak_flux_122',\n",
       " 'int_flux_122',\n",
       " 'err_int_flux_122',\n",
       " 'a_122',\n",
       " 'b_122',\n",
       " 'pa_122',\n",
       " 'residual_mean_122',\n",
       " 'residual_std_122',\n",
       " 'psf_a_122',\n",
       " 'psf_b_122',\n",
       " 'psf_pa_122',\n",
       " 'background_130',\n",
       " 'local_rms_130',\n",
       " 'peak_flux_130',\n",
       " 'err_peak_flux_130',\n",
       " 'int_flux_130',\n",
       " 'err_int_flux_130',\n",
       " 'a_130',\n",
       " 'b_130',\n",
       " 'pa_130',\n",
       " 'residual_mean_130',\n",
       " 'residual_std_130',\n",
       " 'psf_a_130',\n",
       " 'psf_b_130',\n",
       " 'psf_pa_130',\n",
       " 'background_143',\n",
       " 'local_rms_143',\n",
       " 'peak_flux_143',\n",
       " 'err_peak_flux_143',\n",
       " 'int_flux_143',\n",
       " 'err_int_flux_143',\n",
       " 'a_143',\n",
       " 'b_143',\n",
       " 'pa_143',\n",
       " 'residual_mean_143',\n",
       " 'residual_std_143',\n",
       " 'psf_a_143',\n",
       " 'psf_b_143',\n",
       " 'psf_pa_143',\n",
       " 'background_151',\n",
       " 'local_rms_151',\n",
       " 'peak_flux_151',\n",
       " 'err_peak_flux_151',\n",
       " 'int_flux_151',\n",
       " 'err_int_flux_151',\n",
       " 'a_151',\n",
       " 'b_151',\n",
       " 'pa_151',\n",
       " 'residual_mean_151',\n",
       " 'residual_std_151',\n",
       " 'psf_a_151',\n",
       " 'psf_b_151',\n",
       " 'psf_pa_151',\n",
       " 'background_158',\n",
       " 'local_rms_158',\n",
       " 'peak_flux_158',\n",
       " 'err_peak_flux_158',\n",
       " 'int_flux_158',\n",
       " 'err_int_flux_158',\n",
       " 'a_158',\n",
       " 'b_158',\n",
       " 'pa_158',\n",
       " 'residual_mean_158',\n",
       " 'residual_std_158',\n",
       " 'psf_a_158',\n",
       " 'psf_b_158',\n",
       " 'psf_pa_158',\n",
       " 'background_166',\n",
       " 'local_rms_166',\n",
       " 'peak_flux_166',\n",
       " 'err_peak_flux_166',\n",
       " 'int_flux_166',\n",
       " 'err_int_flux_166',\n",
       " 'a_166',\n",
       " 'b_166',\n",
       " 'pa_166',\n",
       " 'residual_mean_166',\n",
       " 'residual_std_166',\n",
       " 'psf_a_166',\n",
       " 'psf_b_166',\n",
       " 'psf_pa_166',\n",
       " 'background_174',\n",
       " 'local_rms_174',\n",
       " 'peak_flux_174',\n",
       " 'err_peak_flux_174',\n",
       " 'int_flux_174',\n",
       " 'err_int_flux_174',\n",
       " 'a_174',\n",
       " 'b_174',\n",
       " 'pa_174',\n",
       " 'residual_mean_174',\n",
       " 'residual_std_174',\n",
       " 'psf_a_174',\n",
       " 'psf_b_174',\n",
       " 'psf_pa_174',\n",
       " 'background_181',\n",
       " 'local_rms_181',\n",
       " 'peak_flux_181',\n",
       " 'err_peak_flux_181',\n",
       " 'int_flux_181',\n",
       " 'err_int_flux_181',\n",
       " 'a_181',\n",
       " 'b_181',\n",
       " 'pa_181',\n",
       " 'residual_mean_181',\n",
       " 'residual_std_181',\n",
       " 'psf_a_181',\n",
       " 'psf_b_181',\n",
       " 'psf_pa_181',\n",
       " 'background_189',\n",
       " 'local_rms_189',\n",
       " 'peak_flux_189',\n",
       " 'err_peak_flux_189',\n",
       " 'int_flux_189',\n",
       " 'err_int_flux_189',\n",
       " 'a_189',\n",
       " 'b_189',\n",
       " 'pa_189',\n",
       " 'residual_mean_189',\n",
       " 'residual_std_189',\n",
       " 'psf_a_189',\n",
       " 'psf_b_189',\n",
       " 'psf_pa_189',\n",
       " 'background_197',\n",
       " 'local_rms_197',\n",
       " 'peak_flux_197',\n",
       " 'err_peak_flux_197',\n",
       " 'int_flux_197',\n",
       " 'err_int_flux_197',\n",
       " 'a_197',\n",
       " 'b_197',\n",
       " 'pa_197',\n",
       " 'residual_mean_197',\n",
       " 'residual_std_197',\n",
       " 'psf_a_197',\n",
       " 'psf_b_197',\n",
       " 'psf_pa_197',\n",
       " 'background_204',\n",
       " 'local_rms_204',\n",
       " 'peak_flux_204',\n",
       " 'err_peak_flux_204',\n",
       " 'int_flux_204',\n",
       " 'err_int_flux_204',\n",
       " 'a_204',\n",
       " 'b_204',\n",
       " 'pa_204',\n",
       " 'residual_mean_204',\n",
       " 'residual_std_204',\n",
       " 'psf_a_204',\n",
       " 'psf_b_204',\n",
       " 'psf_pa_204',\n",
       " 'background_212',\n",
       " 'local_rms_212',\n",
       " 'peak_flux_212',\n",
       " 'err_peak_flux_212',\n",
       " 'int_flux_212',\n",
       " 'err_int_flux_212',\n",
       " 'a_212',\n",
       " 'b_212',\n",
       " 'pa_212',\n",
       " 'residual_mean_212',\n",
       " 'residual_std_212',\n",
       " 'psf_a_212',\n",
       " 'psf_b_212',\n",
       " 'psf_pa_212',\n",
       " 'background_220',\n",
       " 'local_rms_220',\n",
       " 'peak_flux_220',\n",
       " 'err_peak_flux_220',\n",
       " 'int_flux_220',\n",
       " 'err_int_flux_220',\n",
       " 'a_220',\n",
       " 'b_220',\n",
       " 'pa_220',\n",
       " 'residual_mean_220',\n",
       " 'residual_std_220',\n",
       " 'psf_a_220',\n",
       " 'psf_b_220',\n",
       " 'psf_pa_220',\n",
       " 'background_227',\n",
       " 'local_rms_227',\n",
       " 'peak_flux_227',\n",
       " 'err_peak_flux_227',\n",
       " 'int_flux_227',\n",
       " 'err_int_flux_227',\n",
       " 'a_227',\n",
       " 'b_227',\n",
       " 'pa_227',\n",
       " 'residual_mean_227',\n",
       " 'residual_std_227',\n",
       " 'psf_a_227',\n",
       " 'psf_b_227',\n",
       " 'psf_pa_227',\n",
       " 'alpha_1',\n",
       " 'err_alpha',\n",
       " 'reduced_chi2',\n",
       " 'int_flux_fit_200',\n",
       " 'err_int_flux_fit_200',\n",
       " 'ID',\n",
       " 'RA(J2000)',\n",
       " 'Dec(J2000)',\n",
       " 'RA(2000)_1',\n",
       " 'DEC(2000)_1',\n",
       " 'PEAK INT_1',\n",
       " 'MAJOR AX_1',\n",
       " 'MINOR AX_1',\n",
       " 'POSANGLE_1',\n",
       " 'Q CENTER_1',\n",
       " 'U CENTER_1',\n",
       " 'P FLUX_1',\n",
       " 'I RMS_1',\n",
       " 'POL RMS_1',\n",
       " 'RES RMS_1',\n",
       " 'RES PEAK_1',\n",
       " 'RES FLUX_1',\n",
       " 'CENTER X_1',\n",
       " 'CENTER Y_1',\n",
       " 'FIELD_1',\n",
       " 'JD PROCESSED_1',\n",
       " 'Separation_1',\n",
       " 'Source_name',\n",
       " 'RA_1',\n",
       " 'E_RA',\n",
       " 'DEC_1',\n",
       " 'E_DEC',\n",
       " 'Total_flux',\n",
       " 'E_Total_flux',\n",
       " 'Peak_flux',\n",
       " 'E_Peak_flux',\n",
       " 'Maj',\n",
       " 'E_Maj',\n",
       " 'Min',\n",
       " 'E_Min',\n",
       " 'PA_1',\n",
       " 'E_PA',\n",
       " 'RMS_noise',\n",
       " 'Source_code',\n",
       " 'Mosaic_name',\n",
       " 'Separation_1a',\n",
       " 'Name_1',\n",
       " 'RA_J2000_old',\n",
       " 'RA_J2000',\n",
       " 'Dec_J2000_old',\n",
       " 'Dec_J2000',\n",
       " 'e_RAJ2000_1',\n",
       " 'e_DecJ2000',\n",
       " 'S408',\n",
       " 'e_S408',\n",
       " 'Separation_1b',\n",
       " 'RAJ2000_1',\n",
       " 'e_RAJ2000_2',\n",
       " 'DEJ2000_1',\n",
       " 'e_DEJ2000',\n",
       " 'Sp_1',\n",
       " 'e_Sp',\n",
       " 'St',\n",
       " 'e_St',\n",
       " 'MajAxis',\n",
       " 'MinAxis',\n",
       " 'PA_2',\n",
       " 'Mosaic',\n",
       " 'Nm',\n",
       " 'Separation_1c',\n",
       " 'RA(2000)_2',\n",
       " 'DEC(2000)_2',\n",
       " 'PEAK INT_2',\n",
       " 'MAJOR AX_2',\n",
       " 'MINOR AX_2',\n",
       " 'POSANGLE_2',\n",
       " 'Q CENTER_2',\n",
       " 'U CENTER_2',\n",
       " 'P FLUX_2',\n",
       " 'I RMS_2',\n",
       " 'POL RMS_2',\n",
       " 'RES RMS_2',\n",
       " 'RES PEAK_2',\n",
       " 'RES FLUX_2',\n",
       " 'CENTER X_2',\n",
       " 'CENTER Y_2',\n",
       " 'FIELD_2',\n",
       " 'JD PROCESSED_2',\n",
       " 'Separation_1d',\n",
       " 'Name_2',\n",
       " 'PMN_name',\n",
       " 'RA_2',\n",
       " 'Dec_2',\n",
       " 'RA_deg',\n",
       " 'Dec_deg',\n",
       " 'S5_1',\n",
       " 'e_S5_1',\n",
       " 'S8_1',\n",
       " 'e_S8_1',\n",
       " 'Maj_5',\n",
       " 'Min_5',\n",
       " 'PA_5',\n",
       " 'Maj_8',\n",
       " 'Min_8',\n",
       " 'PA_8',\n",
       " 'Alpha_2',\n",
       " 'e_Alpha',\n",
       " 'Epoch',\n",
       " 'FitFlag',\n",
       " 'HAFlag',\n",
       " 'Separation_1e',\n",
       " '_RAJ2000',\n",
       " '_DEJ2000',\n",
       " 'AT20G',\n",
       " 'RAJ2000_2',\n",
       " 'DEJ2000_2',\n",
       " 'S20',\n",
       " 'e_S20',\n",
       " 'S8_2',\n",
       " 'e_S8_2',\n",
       " 'S5_2',\n",
       " 'e_S5_2',\n",
       " 'Ep',\n",
       " 'Q',\n",
       " 'Flags',\n",
       " 'l_m20',\n",
       " 'm20',\n",
       " 'l_m8',\n",
       " 'm8',\n",
       " 'l_m5',\n",
       " 'm5',\n",
       " 'Sp_2',\n",
       " 'Separation_2',\n",
       " 'Separation']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "76-227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T14:56:53.806878",
     "start_time": "2017-07-31T14:56:53.786267"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sed_df = pd.read_pickle(sed_loc)\\ntemp = [i for i,s in enumerate(sed_df.name) if \\'1744\\' in s]\\nsed_df.loc[temp].freq\\nimport importlib\\nimportlib.reload(seds_plot_func)\\n\\ni = 90\\nfreq_arr = sed_df.loc[i][\"freq\"]*1000 # in MHz\\nflux_arr = sed_df.loc[i][\"flux\"]\\nflux_err_arr = sed_df.loc[i][\"flux_err\"]\\nname = sed_df.loc[i][\"name\"]\\nprint(name)\\n\\n#n = 10\\n#freq_arr, flux_arr, flux_err_arr = atca_filter(n, freq_arr, flux_arr, flux_err_arr)\\n\\n\\n# residuals = True\\nseds_plot_func.sed(powlaw,[1,1],freq_arr,\\n                   flux_arr,flux_err_arr, name, \\n                   freq_labels = True, savefig = False, resid=True)\\n\\nplt.close()'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sed_df = pd.read_pickle(sed_loc)\n",
    "temp = [i for i,s in enumerate(sed_df.name) if '1744' in s]\n",
    "sed_df.loc[temp].freq\n",
    "import importlib\n",
    "importlib.reload(seds_plot_func)\n",
    "\n",
    "i = 90\n",
    "freq_arr = sed_df.loc[i][\"freq\"]*1000 # in MHz\n",
    "flux_arr = sed_df.loc[i][\"flux\"]\n",
    "flux_err_arr = sed_df.loc[i][\"flux_err\"]\n",
    "name = sed_df.loc[i][\"name\"]\n",
    "print(name)\n",
    "\n",
    "#n = 10\n",
    "#freq_arr, flux_arr, flux_err_arr = atca_filter(n, freq_arr, flux_arr, flux_err_arr)\n",
    "\n",
    "\n",
    "# residuals = True\n",
    "seds_plot_func.sed(powlaw,[1,1],freq_arr,\n",
    "                   flux_arr,flux_err_arr, name, \n",
    "                   freq_labels = True, savefig = False, resid=True)\n",
    "\n",
    "plt.close()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jey paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''import glob\n",
    "texfiles = glob.glob('../survey_data/*.tex')\n",
    "jey = []\n",
    "for tex in texfiles: \n",
    "    try:\n",
    "        df = pd.read_csv(tex,\n",
    "                         sep='&',\n",
    "                         header=None,\n",
    "                         engine='python', names = ['Source', 'Sample',  'ID', 'z', 'LAS', 'Vpeakc', 'Speak', 'LS', 'log(Lpeak)', 'Refd'])\n",
    "\n",
    "        jey.append([''.join(name.lower().strip().split('$')) for name in df.Source.tolist()])\n",
    "    except:\n",
    "        print(tex)\n",
    "# flatten        \n",
    "jey = [item for sublist in jey for item in sublist]\n",
    "\n",
    "ra = []\n",
    "dec = []\n",
    "n=2\n",
    "for j in jey:\n",
    "    split =re.split(r'(\\d+)', j)\n",
    "    line = split[1]\n",
    "    ra.append(':'.join([line[i:i+n] for i in range(0, len(line), n)])+':00')\n",
    "    #ra.append(split[1]+'.00')\n",
    "    line = split[3]\n",
    "    dec.append(split[2]+':'.join([line[i:i+n] for i in range(0, len(line), n)])+':00')\n",
    "    #dec.append(split[3]+'.00')\n",
    "temp_df = pd.DataFrame(list(zip(jey, ra, dec)), columns=['name', 'RA', 'DEC'])\n",
    "temp_df.to_csv('../survey_data/jey.csv')'''"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
