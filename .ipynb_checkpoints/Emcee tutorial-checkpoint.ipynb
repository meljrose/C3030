{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T16:04:17.854525",
     "start_time": "2017-06-29T14:02:09.399Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-29T16:04:17.855669",
     "start_time": "2017-06-29T14:02:14.599Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !/bin/python\n",
    "\n",
    "# Forming a fit to data with errors with emcee. What I am trying to do is fit to data and producing the posterior distribution functions.\n",
    "# J. Callingham 4/12\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emcee\n",
    "import scipy.optimize as opt\n",
    "import corner#triangle\n",
    "\n",
    "def powlaw(freq,a,alpha): # defining powlaw as S = a*nu^-alpha. Important to have x value first in definition of function.\n",
    "\treturn a*np.power(freq,-alpha)\n",
    "''' real data\n",
    "x = np.array([118., 150., 180., 235.]) # MHz\n",
    "\n",
    "y = np.array([707., 1228., 1858., 3570.]) # mJy\n",
    "\n",
    "yerr = np.array([188., 161., 152., 536.])\n",
    "'''\n",
    "# Making fake data from following parameters\n",
    "\n",
    "alpha_true = 1.678\n",
    "a_true = 1151\n",
    "\n",
    "N = 50\n",
    "x = np.sort(10000*np.random.rand(N))\n",
    "y = a_true*x**-alpha_true\n",
    "yerr = y*0.1 + np.random.rand(N)*(y*0.1)\n",
    "y += np.random.randn(N)*y*0.2\n",
    "#y += abs(yerr * np.random.randn(N))\n",
    "\n",
    "plt.figure(0)\n",
    "plt.clf()\n",
    "plt.errorbar(x,y,yerr, marker = '.', linestyle='none')\n",
    "plt.loglog(x,a_true*x**-alpha_true, color = 'r', linestyle='-', label=\"True model\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Defining likelihood function. This is a simply a gaussian where the variance is underestimated by some fractional amount f.\n",
    "\n",
    "def lnlike(theta,x,y,yerr):\n",
    "\ta, alpha = theta # Model parameters have to be included in lnlike. This implentation makes it versitile.\n",
    "\tmodel = a*(x**-alpha) # Just a straight line\n",
    "\tinv_sigma = 1.0/(yerr**2) # Just making it easier to code the next step.\n",
    "\treturn -0.5*(np.sum((y-model)**2*inv_sigma - np.log(inv_sigma))) \n",
    "\n",
    "# Note I have used the log of f.\n",
    "\n",
    "# This is the values the least-square fit gives us (assuming all errors are correct - i.e. no f factor):\n",
    "\n",
    "poptline,pcovline = opt.curve_fit(powlaw, x, y, p0 = [7000,2.5], sigma = yerr)\n",
    "\n",
    "# Use the scipy.opt model to optimum of this likelihood function\n",
    "\n",
    "nll = lambda *args: -lnlike(*args)\n",
    "p0guess = [poptline[0],poptline[1]]# Guessing the parameters of the model. This can be educated guess (i.e from least-square fit)\n",
    "result = opt.minimize(nll,p0guess, args=(x,y,yerr)) # I used fmin as I find it more versitile than optimize.\n",
    "a_ml, alpha_ml = result['x']\n",
    "\n",
    "# Now to work out the error on these parameters. We first have to define priors for out parameters. This is just the max and min values you think they should take.\n",
    "\n",
    "def lnprior(theta):\n",
    "\ta, alpha = theta\n",
    "\tif -3.0 < abs(alpha) < 4.0 and 1 < a < 10000:\n",
    "\t#if poptline[0]*0.01 < a < poptline[0]*10 and -poptline[1]*0.01 < alpha < poptline[0]*1 and -100.0 < lnf < 1.0:\n",
    "\t\treturn 0.0\n",
    "\treturn -np.inf\n",
    "\n",
    "# Combining this prior with the definition of the likelihood function, the probability fucntion is:\n",
    "\n",
    "def lnprob(theta, x, y, yerr):\n",
    "\tlp = lnprior(theta)\n",
    "\tif not np.isfinite(lp):\n",
    "\t\treturn -np.inf\n",
    "\treturn lp + lnlike(theta, x, y, yerr)\n",
    "\n",
    "# Now implement emcee\n",
    "\n",
    "ndim, nwalkers, nsteps = 2, 100, 500 # ndim = number of parameters in model you are tring to fit. nwalkers need to be >= 100. nsteps \n",
    "\n",
    "# Initialising the walkers in a Gaussian ball around maximum likelihood result\n",
    "\n",
    "pos = [result['x']+ 1e-4*np.random.randn(ndim) for i in range(nwalkers)]\n",
    "\n",
    "\n",
    "# Just making sure everything is running correctly. lnprior should print 0s and lnlike should be \n",
    "print('lnprior', map(lambda p: lnprior(p), pos))\n",
    "print('lnlike', map(lambda p: lnlike(p, x, y, yerr), pos))\n",
    "# The workhorse step. Where all the work is done\n",
    "\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args = (x,y,yerr))\n",
    "sampler.run_mcmc(pos, nsteps)\n",
    "\n",
    "# Now plotting the walks of the walkers with each step, for each parameter. If they have converged on a good value they should have clumped together.\n",
    "\n",
    "fig = plt.figure(2)\n",
    "fig.clf()\n",
    "for j in range(ndim):\n",
    "\tax = fig.add_subplot(2,1,j+1)\n",
    "\tax.plot(np.array([sampler.chain[:,i,j] for i in range(nsteps)]),\"k\", alpha = 0.3)\n",
    "\tax.set_ylabel((r'$a$',r'$\\alpha$')[j], fontsize = 15)\n",
    "plt.xlabel('Steps', fontsize = 15)\n",
    "fig.show()\n",
    "\n",
    "# To me it looks like the burn in period is well and truly over by 150 steps. So I will exclude those. This means the hypthosis of the uncertainty of the flux being underestimated is unlikely.\n",
    "\n",
    "samples = sampler.chain[:,150:,:].reshape((-1,ndim))\n",
    "\n",
    "# Plotting the positerior probability functions.\n",
    "trifig = triangle.corner(samples, labels = [r'$a$',r'$\\alpha$'], truths = [a_true, alpha_true])\n",
    "\n",
    "# Finally to get the final uncertainties you do\n",
    "a_mcmc, alpha_mcmc = map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples,[16,50,84], axis = 0))) # Uncertainites based on the 16th, 50th and 84th percentile. So giving one sigma.\n",
    "\n",
    "print('a =',a_mcmc[0],' + ',a_mcmc[1],' - ',a_mcmc[2])\n",
    "print('alpha =',alpha_mcmc[0],' + ',alpha_mcmc[1],' - ',alpha_mcmc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
