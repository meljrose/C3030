{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MJ Rose with scripts from J. Callingham\n",
    "\n",
    "\n",
    "You can either run this notebook directly, \n",
    "or run it through the [master notebook](analysis_batchrun.ipynb) for batch processing.\n",
    "\n",
    "If you have run this automatically and now want to customize the analysis, make sure to save this under a different name or it might be overwritten by the batch processing script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T15:00:11.504294",
     "start_time": "2017-07-31T15:00:00.125324"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from IPython.display import HTML as html_print\n",
    "import numpy as np\n",
    "import os, glob, subprocess, time, psutil, sys, shutil, fnmatch\n",
    "import pandas as pd\n",
    "import pymultinest,os, threading, subprocess, time, math\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stats\n",
    "import scipy.special as special # For access to the incomplete gamma function.\n",
    "import emcee, corner\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "\n",
    "\n",
    "if not os.path.exists(\"chains\"): os.mkdir(\"chains\") # This is important.\n",
    "# This makes a directory called \"chains\". This is where the walker information\n",
    "# is being stored by Multinest. All Pymultinest does is then read them in.\n",
    "\n",
    "# in case you start script from child directory\n",
    "try:\n",
    "    # Joe's SED plotting \n",
    "    import seds_plot_func\n",
    "    from gpscssmodels import *\n",
    "\n",
    "    # my own\n",
    "    from reduction_funcs import *\n",
    "except:\n",
    "    sys.path.insert(0,'..')\n",
    "    import seds_plot_func\n",
    "    from gpscssmodels import *\n",
    "    from reduction_funcs import *\n",
    "\n",
    "# for nbrun \n",
    "array = np.array\n",
    "\n",
    "# by default, sets up and does analysis form pks1740-649\n",
    "    \n",
    "\n",
    "# set save path\n",
    "image_dir = \"/Users/mmcintosh/Dropbox/ASTRON2017/C3030/model_plots/\"\n",
    "if not os.path.exists(image_dir):\n",
    "\tos.makedirs(image_dir)\n",
    " \n",
    "# set save path\n",
    "model_ev_dir = \"/Users/mmcintosh/Dropbox/ASTRON2017/C3030/model_ev/\"\n",
    "if not os.path.exists(model_ev_dir):\n",
    "\tos.makedirs(model_ev_dir)\n",
    "    \n",
    "if not os.path.exists(model_ev_dir+'modeled_df.pkl'):\n",
    "    # read in data\n",
    "    sedfile = 'sed_df.pkl'\n",
    "    sed_loc = os.getcwd()+\"/\"+sedfile\n",
    "    sed_df = pd.read_pickle(sed_loc)\n",
    "    sed_df.to_pickle(model_ev_dir+'modeled_df.pkl')\n",
    "    \n",
    "# read in data\n",
    "sed_df = pd.read_pickle(model_ev_dir+'modeled_df.pkl')\n",
    "    \n",
    "    \n",
    "# # default source to model\n",
    "interactive = False\n",
    "source_index = 90\n",
    "nwalkers = 50 \n",
    "nsteps = 1000 \n",
    "burnin = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T15:00:11.825171",
     "start_time": "2017-07-31T15:00:11.506453"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# custom function \n",
    "\n",
    "def print_color(s, color='black'):\n",
    "     display(html_print(\"<text style=color:{}>{}</text>\".format(color, s)))\n",
    "        \n",
    "        \n",
    "def get_argnames(func):\n",
    "    return(func.__code__.co_varnames[:func.__code__.co_argcount][1:])\n",
    "\n",
    "\n",
    "def help_unpack(theta):\n",
    "    if isinstance(theta,np.ndarray):\n",
    "        return(copy.copy(theta))\n",
    "    else:\n",
    "        # its probably a generator func from multinest\n",
    "        temp = [theta[i] for i in np.arange(ndim)]\n",
    "        return(temp)\n",
    "\n",
    "def init_repeated_params(arg, param):\n",
    "    ''' if you have something like Snorm, Snorm2, Snorm3\n",
    "    then this function places them at 2x, 4x, 6x ... out \n",
    "    from the original Snorm '''\n",
    "    temp = re.search('\\d', arg)\n",
    "    if temp is not None:\n",
    "        occurance = int(temp.group())\n",
    "        if occurance >= 2:\n",
    "            param = param *2*(occurance -1)\n",
    "    return(param)\n",
    "\n",
    "Prior = namedtuple('Prior', ['guess', 'min', 'max'])\n",
    "def make_prior_dictionary(func, x,y):\n",
    "    argnames = get_argnames(func)\n",
    "    # set up prior information\n",
    "    keys = []\n",
    "    for arg in argnames:\n",
    "        if \"norm\" in arg:\n",
    "            param = Prior(init_repeated_params(arg, np.max(y)), 0.0, 100.*np.max(y))\n",
    "        elif \"alpha\" in arg:\n",
    "            param = Prior(0.7, 0.0, 10.0)\n",
    "        elif \"freq\" in arg:\n",
    "            param = Prior(init_repeated_params(arg, x[np.argmax(y)]), 0.0, 20e+3)\n",
    "        elif \"p\" in arg:\n",
    "            param = Prior(-0.3, -10.0, 10.0)\n",
    "        elif \"beta\" in arg:\n",
    "            param = Prior(3, 1.0, 10.0)\n",
    "        elif \"gamma\" in arg:\n",
    "            param = Prior(1., 0.0, 10.0)\n",
    "        elif 'q' in arg:\n",
    "            param = Prior(1., 0.0, 10.0)\n",
    "        else:\n",
    "            param = Prior(1., 0.0, 20e+3)\n",
    "        keys.append(param)\n",
    "    dictionary = OrderedDict(zip(argnames, keys))\n",
    "    return(dictionary)\n",
    "\n",
    "def check_if_in_prior(theta, prior_dict, set_to_nearest=False, set_to_random=False): \n",
    "    ''' if parameters are within the prior boundaries, returns them. Otherwise, it returns False.\n",
    "    set_to_nearest replaces the out of bounds value with the nearest boundary'''\n",
    "    params = help_unpack(theta)\n",
    "    for i, (name, prior) in enumerate(prior_dict.items()): \n",
    "        if not (prior.min <= params[i] < prior.max):\n",
    "            #if set_to_nearest: \n",
    "                # if not within prior bounds, set the param equal to the closest boundary\n",
    "                #params[i] = min([prior.min, prior.max], key=lambda x:abs(x-params[i]))\n",
    "            if set_to_random:\n",
    "                # if not within prior bounds, set it to a random value in between max & min\n",
    "                params[i] = np.random.uniform(prior.min,prior.max,1)[0]\n",
    "            else:\n",
    "                return(False)\n",
    "    return(np.array(params))\n",
    "\n",
    "# for both emcee and multinest\n",
    "def lnlike(theta, ndim, nparams):\n",
    "    #(theta,x,y,yerr,func):\n",
    "    params = help_unpack(theta)\n",
    "    inv_sigma = 1.0/(yerr**2)\n",
    "    loglike = -0.5*(np.nansum((y-func(x,*params))**2*inv_sigma - np.log(inv_sigma))) \n",
    "    \n",
    "    # the model will return -0.0 if it gets a divide by zero error, \n",
    "    # which happens if the parameters are too big\n",
    "    if loglike == -0.0:\n",
    "        loglike = -np.inf\n",
    "    return(loglike)\n",
    "\n",
    "def emcee_lnprior(theta, prior_dict): \n",
    "    params = check_if_in_prior(theta, prior_dict)\n",
    "    if not isinstance(params, np.ndarray):\n",
    "        return(-np.inf)\n",
    "    else:\n",
    "        # flat prior\n",
    "        return(0.00)\n",
    "   \n",
    "def multinest_lnprior(cube, ndim, n_params):\n",
    "    '''This transforms a unit cube into the dimensions of your prior\n",
    "    space to search. Make sure you do this right!'''\n",
    "    for i in np.arange(ndim):\n",
    "        cube[i] = cube[i] * emcee_fit[i]*sig\n",
    "    \n",
    "        \n",
    "def emcee_lnprob(theta, ndim, n_params, prior_dict):\n",
    "    lp = emcee_lnprior(theta, prior_dict)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    prob = lp + lnlike(theta, ndim, n_params)\n",
    "#     if np.random.rand() < 0.001:\n",
    "#         print(prob, theta)\n",
    "    return(prob)\n",
    "\n",
    "def redchisq(ydata,ymod,sd,parafreq_arrm):\n",
    "    chisq=np.sum(((ydata-ymod)/sd)**2)\n",
    "    freq_arr=ydata.size-parafreq_arrm-1\n",
    "    return [chisq, chisq/freq_arr]\n",
    "\n",
    "def populate_walkers(ndim, scale, nwalkers, prior_dict, guess=None, set_to_random=False):\n",
    "    # initializes random positions, running it through the prior\n",
    "    # do I need to pass a random seed? \n",
    "    # if set_to_random = false, then it adds noise to 0.0 for out of bound guesses\n",
    "    pos = []\n",
    "    counter = 0 \n",
    "    while len(pos) < nwalkers:\n",
    "        counter +=1\n",
    "        # generate random scatter\n",
    "        test_theta = [(prior.max-prior.min)*scale*np.random.uniform(-1,1) for name, prior in prior_dict.items()]\n",
    "        #print(test_theta)\n",
    "        # add it to an initial guess if you have one\n",
    "        if guess is not None:\n",
    "            new_guess = check_if_in_prior(guess, prior_dict, set_to_random=set_to_random)\n",
    "            if isinstance(new_guess, np.ndarray):\n",
    "                #print('guess',guess[-1])\n",
    "                test_theta += new_guess\n",
    "                #print('theta',test_theta[-1])\n",
    "        # if this is within the prior, keep it\n",
    "        test_theta = check_if_in_prior(test_theta, prior_dict)\n",
    "        if isinstance(test_theta, np.ndarray):\n",
    "            pos.append(test_theta)\n",
    "        if counter > 1e+5:\n",
    "            print('check your scale, populate_walkers has reached 1e+5 iterations')\n",
    "            return(None)\n",
    "    return(pos)\n",
    "\n",
    "\n",
    "def make_plot_labels(func):\n",
    "    input_list = func.__code__.co_varnames[1:]\n",
    "    labels = []\n",
    "    for i in input_list:\n",
    "        if 'freq' in i:\n",
    "            i=i.replace('freq',\"\\\\nu\") \n",
    "        temp = i.split('_')\n",
    "        if len(temp) > 1:\n",
    "            labels.append(temp[0]+'_{{{0}}}'.format(temp[1]))\n",
    "        else:\n",
    "            if i in ['alpha','beta']:\n",
    "                i = \"\\\\\"+i\n",
    "            match = re.match(\"([a-z]+)([0-9]+)\", i, re.I)\n",
    "            if match:\n",
    "                items = match.groups()\n",
    "                labels.append('\\\\'+items[0]+'_{{{0}}}'.format(items[1]))\n",
    "            else:\n",
    "                labels.append(i)\n",
    "    labels = [\"$\"+i+\"$\" for i in labels]\n",
    "    return(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T15:00:11.830980",
     "start_time": "2017-07-31T15:00:11.827399"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_list = ([singhomobremss,singhomobremsscurve,singhomobremssbreak,singhomobremssbreakexp,\n",
    "#                singinhomobremss,singinhomobremsscurve,singinhomobremssbreak, singinhomobremssbreakexp,\n",
    "#                doubhomobremss,doubhomobremsscurve, doubhomobremssbreakexp,\n",
    "#                singSSA,singSSAbreakexp,\n",
    "#                doubSSA,doubSSAbreakexp,\n",
    "#                tripSSA,quadSSA,\n",
    "#                powlaw,powlawbreak,powlawbreak_nophys,powlawexp,\n",
    "#                internalbremss,\n",
    "#                curve,curvepowlaw,duffcurve,logduffcurve])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares, Emcee, Multinest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T16:14:15.364358",
     "start_time": "2017-07-31T16:14:14.917226"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = sed_df.loc[source_index][\"freq\"]*1000 # in MHz\n",
    "y = sed_df.loc[source_index][\"flux\"]\n",
    "yerr = sed_df.loc[source_index][\"flux_err\"]\n",
    "name = sed_df.loc[source_index][\"name\"]\n",
    "\n",
    "\n",
    "indx = [i for i,x in enumerate(x) if (x > 1000 or x < 300)]\n",
    "x = x[indx]\n",
    "y = y[indx]\n",
    "yerr = yerr[indx]\n",
    "\n",
    "\n",
    "# fix an incorrect name in the data\n",
    "if name == 'pks1740-649':\n",
    "    name = 'pks1718-649'\n",
    "if name == 'j174425-5144':\n",
    "    name = 'pks1740-517'\n",
    "\n",
    "\n",
    "\n",
    "# add in extra data for this particular one\n",
    "if source_index == 90:\n",
    "    paths = glob.glob('../survey_data/1740-517*/*.txt')\n",
    "    data = sorted_nicely([path for path in paths if 'std' not in path])\n",
    "    dataerr = sorted_nicely([path for path in paths if 'std' in path])\n",
    "    for path in data: \n",
    "        temp_txt = np.loadtxt(path)\n",
    "        freq, flux = list(zip(*temp_txt))\n",
    "        x = np.append(x,np.array(freq)*1000)\n",
    "        y = np.append(y,flux)\n",
    "\n",
    "    for path in dataerr: \n",
    "        temp_txt = np.loadtxt(path)\n",
    "        freq, flux = list(zip(*temp_txt))\n",
    "        yerr= np.append(yerr,flux)\n",
    "\n",
    "rand_seed = 45\n",
    "np.random.seed(rand_seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-31T16:14:17.277689",
     "start_time": "2017-07-31T16:14:16.495740"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1412859e8>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAFwCAYAAABjM9sPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X+M3PV95/Hnxza2E36sbTIGQhJjuwF5o0bNLhjjIO4u\n0Pw8rEghtjeQyuhKOJBaaS9hoUlb3bVAyPpUpEYHyVEVpBDGJoHqkrZpoaDKJCzeZDdppNgpZQ2k\nEPBuAC+EFP/An/vj+x1mdjyzP+fHd2aeD2m13vl+d+ZjPnj2tZ8f70+IMSJJkpQVi5rdAEmSpFKG\nE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCktHU5CCOtCCD9qdjskSVLtLGl2A+YjhPABYFv6ZU8z2yJJ\nkmortHKdkxBCD/CjGGNLjwBJkqQif6hLkqRMaei0TjrSsTXGeNM091wGXAaMASsAYow7G9NCSZLU\nbA0LJyGEK4C7gF0z3LM1xri15LFLQwgPxRg/3IBmSpKkJqv7tE4I4bYQwv1ABF6a5r4VwP3AQOnj\nMcZH0uvX1LOdkiQpG+oeTmKMN8UYt8YYHwAOTXPrVmAsxvhMhWsPA9fWo32SJClbsrQg9tPAgSrX\nngZ6QginNbA9kiSpCbIUTs6nejg5UHKPJElqY1kKJ11MP+0D6e4dSZLUvlqlQmwhtKwCCCGsJVmD\nchkQQwgPAaPAl2OMk81poiRJqoVWCSdTxBifBqrWSpEkSa2rJcPJfIUQTgc+AjwDvNHc1kiS1FKW\nA+cA/xhjrFoapBayFk6qrSkpPP7yAp//I8A3F/gckiR1siuB++r5AlkKJwdI15RUsKrknoV4BuDe\ne+9lw4YNC3yqhevv7+f222/PxHPO9ftmc/9M91S7XqvHm6HWbVnI883le+vZn9Ndq/S4/bnw77U/\nK+vk99xa9Of+/fu56qqrIP1ZWk9ZCiejwMoq1wpn7Pxkga/xBsCGDRvo6elZ4FMtXFdXV83bMd/n\nnOv3zeb+me6pdr1WjzdDrduykOeby/fWsz+nu1bpcftz4d9rf1bWye+5terPVN2XRWRpK/HDVK9j\ncgEw0sC2NERfX19mnnOu3zeb+2e6p9r1uT6eJbVu40Keby7fW8/+nO5a1vvU/pzbtU7rz4U8Z6Pf\nc1utP0OMsXEvFsKPgB/GGK+rcG0FybRNb7obp/TaGMk24b9a4Ov3ACMjIyOZSfJauC1btvCd73yn\n2c1Qjdif7cX+bB+jo6P09vZC8nN6tJ6v1eiRk5XA6ZUuxBgPAdcAXy99PD2p+KmFBhNJktQa6r7m\nJIRwA8m0TA+wFjgnHUE5AOxODwQEIMb4QAjhUAjhNmCMZK3JqhjjR+rdTrWurA8la27sz/Zif2o+\nGjqt02yFaZ1LLrmErq4u+vr6/IcjSdI08vk8+XyeyclJ9uzZAw2Y1unIcOKaE0mS5qad15xIkiRN\ny3AiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyJUsH/zVMf3+/dU4kSZqF0jonjWKdE0mSNCPr\nnEiSpI5lOJEkSZliOJEkSZliOJEkSZliOJEkSZliOJEkSZliOJEkSZliETaLsEmSVJVF2OrMImxS\n+7jzzju5/vqvAEuB5cDh9GOS1avP4uMf/wSDgwPkcrmmtlNqFxZhk6RpfPWrX+X66/8nyeBvKLmy\nBFjK+PgL3HPP/2b16nWEEMo+TiaE8wjhHEJ4B3feeWcz/gqSpmE4kdRy/vAP/xdwCnAv8HPgp8B+\n4Bvp44uBs4Bfk4yqlPoNsBbIA11cf/2fvhVcVq5c2aC/gaTpGE4ktaBCMNlEceRkEXARxYCyHFgD\nnJF+Lv34edm9awA4dOjQCSMt1113XaP+UpJShhNJLWgZSTCpZFN6fWn6eVmFr5eW3HtS+nVpeCn6\n2te+9lZQ2b9/f23/GpIqMpxIakHLmLrWpNSi9PpJTA0ny8v+XLh3edm18qCyBngPAN3d3Y6mSA1g\nOJHUgt4Aqu00PJ5eL+zeKf1z6Ufh3sLXlUJM6YhLIaicMWU05fOf/3zN/3ZSpzOcSGpBR4Anqlx7\nIr1eCCVHqB5OnqhyrXzEpRBYlgJvp3T65y/+4i8IIbBpU7VpJklzZTiR1HL+5E9+D7gKeJxk9IP0\n8+PAZ4FXgOeBZ0s+flXy58Ml975GsoOnUkgpDyzLKY6klE7/rGbv3r2EEAp1ICQtQEdWiJXU2v7s\nz/4MgD//889wYhG2l4DXmTrtswp4Of3zWSRbja8k2Wp8nGTHzrMl909dFDt1fcvSkq9Dyesk3zM6\nOkoIyfU77rjD9SnSPHRkhdhLLrnE8vVSG5qYmGBgYJDh4X289toRnn/+3zl+/CjJSMcxkimeRSSL\nZQ+TBI2VwDjwTPos7yAZZSl1FsUdPqXhZFn6uTBNFNPXgNKw00nvs2o/peXr9+zZAw2oENuR4cTy\n9VJn6ev7A3bt+ijwz8A+kpGTN4Fu4D8Bf0ASLF6jOMICSQhZmd5bOFfk3RRnxJeVfYYkqJSGlAj8\ngqVLl3L48GGkVmX5ekmqob/8yz/lnHMGgU8C3wW+k37+JOecs5M77hhI73wH8NvAuSTTNO8kmf0u\nBJMVwL+TjIq8TuUdQaU7foo7fY4cOWK9FGmWXHMiqe3lcjmGh7+dTvncyrFji1my5E02buxmcPDb\n5HI5rrjiCgYGBvn7v9/D+PhxkhGPQq2Ut5Essj2UPuNqkqmgwvTPezix7sqysq8L61iepbu7G3C6\nR6rGcCKpI+RyOe6+e+ecrp9xxhmMj7+N4s6cwuhI6eLZdwG/SP98Ksni23LLKS6eLYSUg4QQDChS\nBU7rSFIVBw8eJMZn2Lfv/5GMnETgNJJpn3NIFso+l969gmTNyrPAixSDTKHOSvl0T3Lmz7nnntuo\nv47UMhw5kaQZbNiwgRj/HYCVK1dy6FAXScA4Nf0oHU1ZTrIGpfD1mUzd1lyY7klGUv7t344gaSrD\niSTNwSuvvAJAV1cXr766kiSkFEZTyqd8zgJeINkd9K6yZyoNKZJKGU4kaR4mJ5MdPBMTE6xevYFk\nrcmpwHnAUZLpnOdIQsgiiqGlsOYkkgST8oWzklxzIkkLkMvliPFXbNvWQ7Lm5DhwMsUzeALwH+nd\nSyiW0C8980dSKcOJJNXArl27iPEZLrxwFfAqxcWz7yEJKYtJqtRCsni29JwfSaUMJ5JUQ0888QQx\nPsNXvvL7TA0p60lCymkU66Us5b3vXVr5iaQO1pHl6z1bR1KjXHrppTz66BgnHlD4S9773nN48skn\nm9o+aSaerVNnnq0jSdL8eLaOJEnqWIYTSZKUKYYTSZKUKRZhk6QWFEKhsuwakkJuy0jK5h9hyZLn\nOXr0aNPaJi2UIyeS1GKKwQSSWim/AV4neUs/lWPH1hLCO5iYmGhK+6SFMpxIUstZU/bn54ADFEZO\nki3Lq1i9+gLOOOOMJrRPWhindSSp5SyjGFBKDxp8tuTx5QCMjycjLZ1UNkKtz5ETSWo5y0o+1pRd\nK5TEP0wSUJYCa8qmgqRsM5xIUss5jAFF7cxwIkkt5zDJ+pLSkGJAUfswnEhSy3mWZOFrIaQYUNRe\nXBArSS0mxlhW5wQKC2CTr6dfJFsIKC6SVVY5ciJJLagYLAqjKI6gqH10ZDjp7+9ny5Yt5PP5ZjdF\nkuZtx44vAEPMHFDejgFF85XP59myZQv9/f0Ne83QScN6IYQeYGRkZISenp5mN0eSFmRiYoKLLtrG\n2NgtwGaSQLKUJHwUgsiLFBfOHqZSuXt41ikezWh0dJTe3l6A3hjjaD1fqyNHTiSpHeRyOYaGdrNj\nx4N0d3+cyiMoZwInkQSTMzlxBCUZZXEERVliOJGkFpbL5RgcHGDjxu5pAso7gdNJRlHeld7zWvoB\ncBrwXkI4m/379zf6ryCdwN06ktTCxsfH2bx5O2NjtwKDQEg/ynfoQPKW/xywCniBZArorCn3dXd/\njIsvfjePPfZYA1ovVebIiSS1sBtv3JkGk00koQQgUnkE5W0kIygvkwSTI2XPlnz/97//fT72sY/V\nve1SNYYTSWphw8P7gAsrXKkUUJYCp5CMqhwB1gG7gJ8DPwX2A3lgHf/wD/9Q97ZL1RhOJKmFHTu2\nmOKISblqIyiFrcb3MnXEZRFwEfANTqyVIjWO4USSWtiSJW+ShJBKjtPd/XHe/vYJKgeUTVW+b1N6\nXWoOw4kktbCNG7uBvVWu7mXjxm5ef/11TjvtFYoBpRBSqo24LMJwomYynEhSCxscHGD9+i+SVIo9\nnj56HBhi/fovMTg4AMDk5CRr1y4iCSiFkFJ9xCW5LjWH4USSWtjUQmyXc+65W+juvpwdOx5kaGg3\nuVzurXsPHDjARz+6geI6lCeqPOsTnLiTR2oc65xIUovL5XLcfffOWd37ve99j8HBQW688UbgKpLF\nr5tIflc9ThJMPsuyZS/Wq7nSjBw5kaQOMzAwQIyRZcueBz4DbADen37+DMuWPc8bbzito+Zx5ESS\nOpQBRFnlyIkkScoUR04kSbMyMTHBwMAgw8P7OHZsMUuWvMnGjd0MDg5MWXgrLZThRJI0o+Ii2rMo\nlsJfxr59/8Y999zH979/Px/84Aeb20i1Dad1JEnT+upXv1oSTF4AngEOpx/LgZO5+OIrHT1RzYQY\nqxXhaT8hhB5g5JJLLqGrq4u+vj76+vqa3SxJyrQQ1gKvAxNlV9ZQLIX/BkltlGfppJ8rnSCfz5PP\n55mcnGTPnj0AvTHG0Xq+ZkeGk5GREXp6eprdHElqCSGcR1JNNgkfRauAUykPKGeeeZgXXnih4e1U\nfY2OjtLb2wsNCCdO60iSZlB+mjEkweTlsvuSs3pefPFFvvnNbzasdWo/hhNJ0gwOA0cpLoR9F0kw\nOZ1kJKWw/qRwfQ1XXXVVc5qqtmA4kSTNoPSwwOXASUAX8FL69bPAb0jWpSwimep5LyG8g4mJ8nUq\n0swMJ5Kkad1xxwDJyMkRkhGSpcAKkpDyBrAYeA54k2RtSkg/TmH16tUGFM2Z4USSNK3rrruOk09+\nheIUzkkkUzjvJPkx8mZ6Z+UpntWrVze8zWpthhNJ0ox+/etfpyHjJYrhYxnw7rI7SwPKcgoBJYTQ\nwNaq1RlOJEmzcvDgQfbtGyZZW/IGJ+7gKTCgaGEMJ5KkWduwYQN33PHHFBfIVgoo64BdwM+Bn6af\n88A6A4pmxXAiSZqT6667jtWr/4PKAWUNcC+wiULdk+RHzUXANzhxlEU6kQf/SZLm7ODBg+koSCFs\nLE8/R5JgUskmkikeaXqGE0nSvMQYqwSUalM3i0rukaoznEh1MjExwcDAIMPD+zh2bDFLlrzJxo3d\nDA4OeHqr2saJASVQrHVS7jjJIllpeoYTqQ7Gx8fZvHk7Y2O3AoMkb9TH2bdvmMce28bQ0G4DitrG\n+Ph4us24EFCeIFljUu4JDCeaDRfESnVw440702BSvihwE2NjtzAwMNi8xkk1lsvlGB8fJ9lC/Cxw\nFfA4yUgJ6efHgc8y9VRjqTJHTqQ6GB7eRzJiUsmFDA/f3MjmSDVXadpyx44vcM89/5skgHyG4i6e\nQs2T59IQI03PcCLVweHDMN2iwGPHFjewNVJtTTdtuX79CN/97v9hcPCvXW+leTOcSDU2Pj7OL37x\nDNMtClyy5M0Kj0utYeq0ZUFx2nJw8K+5++6dTWqd2oFrTqQampiY4IMf3MrRo+cDe6vcNcTGjd2N\nbJZUU8m05YVVrl6YXpfmz3Ai1cj4+DgXXbSNp55aBOwEvggMUb4o8KSTfp/BwYFmNVNasGRa0mlL\n1Y/hRKqR4lD3KcBqYDfwIHA5sCX9/De8+93vcd5dLS2ZloxVrjptqYVzzYlUI8UdOoU37hzJCEqp\n4yxffnmjmybV1MaN3ezbt5fKZer3Om2pBXPkRKqR4lB3N9XXm/jGrdY3ODjA+vWVpi2HWL/+S05b\nasEcOZFqYGJigoMHf0kyYjIAbANuIVk0uIjiG/efMDi4u3kNlWogl8sxNLQ7rXNyc9l2Yasfa+EM\nJ9ICFWo+TE6+j2LZ7t0kUzw3A4uB1/it34o8/vi3fONWW8jlcm4XVt0YTqQFKGwdThbCvpepIyY7\nKR0xefzx+w0mkjQLhhNpnopVMheRjJYEThwxOUZX1y8ZGnrYYCJJs9SR4aS/v5+uri76+vro6+tr\ndnPUoopbh2+lWPPhxB06Z5yxxWAiqWXl83ny+TyTk5MNe82ODCe33347PT09zW6GWtyJW4ctVS+p\n/RR+kR8dHaW3t7chr+lWYmme3DosSfVhOJHm4cStw5VqPvzAmg+SNA8dOa0jLYRbhyWpvgwn0hwV\nF8Kux63DklR7hhNpjooLYd06LEn1YDiR5mjqcfFuHZakWnNBrDRHHhcvSfVlOJHmKNka7NZhSaoX\nw4k0Rx4XLzVXCIEQziGEcwnh/YRwXvp1YPv27c1unmrANSfSHExMTDAwMMjixYs47bTreeONYyxf\nfgpnnnkamze/3+PipToLIQDrgG+S7JILJL8c7AWuYvfu3QDs2rWrWU1UDThyIs3CxMQE27dfz9ln\nX8I993yKJ598mFdf/TFHjvwLr756O2++eZTBwQGDiVR3a4B7gU0UF6YXDt/8BrCG3bsfa1LbVCuG\nE6mKiYkJrr76Bs477zLOPvsSdu9+naNH/5oT3xQ3MTZ2CwMDg81rrNQxlpL8G6xkU3r95HSERa3K\ncCJVMD4+zkUXbUtHSX6Ho0fvBn5F9TfFC9P6J5LqazmVD9mE5EfacmAZcBYnn3xyw1ql2jKcSBUU\nq8BuAvaTzG2X1jcptyitfyKpvg4z3Vb+5PpRYBm/+c07+MEPftCwlql2DCdSBckoyIXpV4VQYn0T\nqfkOk5xpVckT6fUjJNM7y7j44v/coHaplgwnUgVTq8AWQon1TaTmmwSuAh5n6lb+x4HPpteTkZPk\n42zXn7Qgw4lUwdQqsIVQMgBUqm/yA+ubSA1zCHgVuBLYALw//XwlMA6cBrwtvfdI+tnpnVZjOJEq\nmFoFthBKngLywIPAfwV+l5NO+m22b9/F0JD1TaRGiDGSLE6PTJ1m/TXJWVe7gX8FfkqyXuw+4FQu\nvvjiBrdUC2E4kSqYWgX2dJI3vAeA7Zx00j9x7rlvsmPH7/D88/9MPv9Vg4nUQElAeZZkZOQwyfTN\nUirXP9lMUv/knU7vtBArxEplpq8Ce77F1qQMOPPMM3nxxWdJirIBnExSiK2Si9Lra5iYmPDfbwsw\nnEglxsfH2bx5e7qNeJBCaewjR4bJ5b5oMJEy4oUXXigZCYkkoyfT1T9ZBsDq1WcR47H6N1AL4rSO\nVGJqfROrwEpZNj4+TnF65yjT1z85SlKg7V1O77QAw4lUYmp9k3JWgZWyJJfL8dGPfpRkMewRpq9/\nUlifshQ4jTvvvLMxjdS8GE6kElPrm5SzCqyUNd/73veAl0jCx+c5cav/EPAFiuFkObCS66//H41v\nrGbNNSdSiWJ9k0oBxSqwUhbFGAlhEcmPtDuBP0//fAx4B/DL9ON0isXZziCEkO78UdY4ciKVmFrf\npJxVYKWsOvvsdwLPAXuAMeCZ9POe9PFCfZTSrcfvaUZTNQuGE6nE1PomU4eGrQIrZddzzz1HctQE\nnLgwtnTE8yDwBsXTi5VFTutIJXK5HENDuxkYGGR4+GaOHVvMkiVvsnFjN4ODVoGVsiyZ3gkUa58s\nTz+vIdnVcyrwGsn6k4DhJLsMJ1KZXC7H3XfvbHYzJM3Dhz70IR599FGSQFIaQAoBZWn6uXBdWeS0\njjraxMQEV199A+ed9xG6ui5i2bLfpqvrA5x33mVcffUNTExMNLuJkubgkUceKfmqfHrnJIqHAb5W\n8mdlTcuOnIQQPkfx/7z1wJdjjJNNbJIyrlCWfnh4X7ol+De88MIEr732dZJqsL8CvsKRI6O8+upL\nPPnkMN/+9ocYHr6fDRs2NLfxkmbt3nvv5aqrruLE0ZN3koyanAK8jNM62dWS4SSEcAXQE2P87+nX\nXcAjwPlNbZgyq3JZ+i8AnyKpBjsObAduBXZSKFv/61/v5cILtzM29k+uN5FaxJVXXsn111/Pq6/C\niaMnq0iCCcALDW2XZq9Vp3X+CLi/8EU6YvJyCOHS5jVJWVa5LP3+9GtIAkmlsvUX8dprd1i2Xmox\nk5OTFEvbv0Gxvsmpb91zyikrmtI2zazlwkkIYQXwAeBHZZcOAZ9ufIvUCiqXpS+tBjtd2fqLLFsv\ntaDx8XFCOEixOmwhoKwhhOUcOPBkU9un6ho6rRNC6AG2xhhvmuaey4DLSKrnrACIMZZunVhX5Vtf\nmeaaOlzlsvSl1WAtWy+1m1wux8GDv5iy1qxYGsATxrOsYeEkXSdyF7Brhnu2xhi3ljx2aQjhoRjj\nh9OHVgHEGF8t+/ZDhWtSucpl6QvVYDcxNaiUs2y91KosDdCa6j6tE0K4LYRwP8k7/0vT3LeCZB3J\nlBKcMcZH0uvXlN1/Wu1bq3ZVuSz9APBF4HFgQ4XrBU9Ytl6SGqju4STGeFOMcWuM8QGS0Y1qtgJj\nMcZnKlx7GLg2/XNhmXX5KMkKpgk/6myVy9KfDnyBU065lnPOGSaE3wN+wNSy9Y+zfv0fW7Zekhoo\nS1uJPw0cqHLtaaAnHS0p3FO+zHrVNN+vDjd9WfpHyeVyJXVQbrVsvSQ1UZbCyflUX49SCB3nxxgf\nDSGMkvzaW2otyVnZUkUzzT07Ny1J2ZClrcRdTD/tA8XRki9TnOYhhLAOiDHGR+vUNkmS1CBZGjmZ\nTiG0FHbqPBBCWBVCuCG91gtYgE2SpDbQKuHkBDHGu0q+vKvqjZIkqaW0bDiRqik/4M+iS5LUWrIW\nTqoddFB4/OUq1+ekv7+frq6uKY/19fXR19dXi6dXE1U+4O84+/YN89hj2xgacueNJM0kn8+Tz+en\nPJacV9QYIcbyExvr+GIh/Aj4YYzxugrXngJGYozbKly7DHiI5CTinyzg9XuAkZGREXp6eub7NMqw\nq6++gXvuKZw0XG6IHTsedEeOJM3D6Ogovb29AL0xxtF6vlaWduuMAiurXCucsTPvYKLOUPmAv4IL\nPcBPklpAlsLJwyS1Tiq5ABhpYFvUok484G8CuAH4BPBJnnrqF1x99Q1MTEw0pX2SpJllKZx8CyCE\nsLbCtSuArze2OWpFxQP+AMaBbcCngL8FvsORI//CPfd8iosu2mZAkaSManQ4WcmJlV0BiDEeAq6h\nLISkJxU/FWP8q/o3T61u6gF/O4FbSdafFEZTFgGbGBu7hYGBwSa0UJI0k7rv1kkLpV0A9JCUmD8n\nXRh7ANidHggIvFVc7VAI4TZgjGStyaoY40fq3U61h8HBAR57bBtjY7cAPyPZsVPJhQwP39zAlkmS\nZqvu4STGOKetETHGR4BH6tQcoLiV2O3D7af0gL/77nuRI0dClTsXpetTJEnTKWwrbtutxM3mVuLO\n8r73fYJ9+/6WqQtkC47T3X05P/vZ3zW6WZLUkjp1K7E0KxMTE1x99Q28732f4LzztvC+932i4g6c\nqetPyu1Nr0uSsiZrFWKlac2lAuzU9ScXkmTx48Be1q//EoODu5v115AkTcORE7WUG2/cmQaTmXfg\nFNaf7NjxIN3dl3PuuVvo7r6cHTsetIy9JGWYIydqKUmF1/IdOBPpYz/jvvteZHj4E1MO+rNcvSS1\nFkdO1FJOrABbWmjt7zhyZJR9+75roTVJamGGE7WUqRVgwUJrktR+OjKc9Pf3s2XLlhOOg1Z2FXbo\nPP/888BQyRUP+pOkesrn82zZsoX+/v6GvaZ1TpR5U3forAO2AzeTjJZ8EvhO1e8999wt/Ou/Vr8u\nSZod65xIJabu0FkN7Ab+Bric5BSEagH7eDoNJElqJYYTZV4yNVM6dZMjWWvyd8BHmTrNU8pCa5LU\nigwnyrwTd+iUupGTTvpvJAHlePrYcWAoLbQ20IgmSpJqyDonyrziDp1KAeV01q49m82bH2R4+GaO\nHVvMkiVvpnVOLLQmSa3IcKLM27ixm3379pKsOSm3l82bP2ChNUlqI07rKPMGBwdYv/6LOHUjSZ3B\nkRNlXuGMnIGBQaduJKkDdGSdk0suuYSuri76+vro6+trdrMkScqsfD5PPp9ncnKSPXv2QAPqnHRk\nOLEImyRJc2MRNkmS1LEMJ5IkKVMMJ5IkKVMMJ5IkKVMMJ5IkKVMMJ5IkKVMMJ5IkKVMMJ5IkKVMM\nJ5IkKVM68myd/v5+y9dLkjQLpeXrG8Xy9ZIkaUaWr5ckSR3LcCJJkjLFcCJJkjLFcCJJkjLFcCJJ\nkjLFcCJJkjLFcCJJkjKlI4uwKdsmJiYYGBhkeHgfx44tZsmSN9m4sZvBwQFyuVyzmydJqjPDiTJl\nfHyczZu3MzZ2KzAIBOA4+/YN89hj2xga2m1AkaQ257SOMuXGG3emwWQTSTCB5H/TTYyN3cLAwGDz\nGidJaoiOHDnxbJ3sGh7eRzJiUsmFDA/f3MjmSFLHa8bZOh0ZTm6//XbP1smoY8cWUxwxKbcovS5J\napTCL/IlZ+vUndM6ypQlS94Eqh1GeTy9LklqZ4YTZcrGjd3A3ipX96bXJUntzHCiTBkcHGD9+i8C\nQ8Dx9NHjwBDr13+JwcGB5jVOktQQHbnmRNmVy+UYGtqd1jm5uazOiduIJakTGE6UOblcjrvv3tns\nZkiSmsRpHUmSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCkdWYSt\nv7+frq6ut05alCRJleXzefL5PJOTkw17zRBjtRNg208IoQcYGRkZoaenp9nNkSSpZYyOjtLb2wvQ\nG2McredrOa0jSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAi\nSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyZUmzG9AM\n/f39dHV10dfXR19fX7ObI0lSZuXzefL5PJOTkw17zRBjbNiLNVsIoQcYGRkZoaenp9nNkSSpZYyO\njtLb2wtdZcdGAAAJn0lEQVTQG2McredrOa0jSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAi\nSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIy\nxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAi\nSZIyxXAiSZIyZUmzG9AM/f39dHV10dfXR19fX7ObI0lSZuXzefL5PJOTkw17zRBjbNiLNVsIoQcY\nGRkZoaenp9nNkSSpZYyOjtLb2wvQG2McredrOa0jSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIy\nxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAi\nSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIy\nxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIyxXAiSZIypaXDSQhhXQjhR81uhyRJqp0lzW7A\nfIQQPgBsS7/saWZbJElSbbXkyEmM8ccxxpuA+5vdFkmSVFstGU4kSVL7mte0TgihB9iajl5Uu+cy\n4DJgDFgBEGPcOZ/XkyRJnWPO4SSEcAVwF7Brhnu2xhi3ljx2aQjhoRjjh+fVUkmS1BFmPa0TQrgt\nhHA/EIGXprlvBclakIHSx2OMj6TXr5lfUyVJUieY9chJ6RROCOGPprl1KzAWY3ymwrWHgWtJRl4I\nIVwK3DiLlz9UOgojSZLaVz0WxH4aOFDl2tNATwjhNEhGU2KMH57Fh8FEVeXz+WY3QTVkf7YX+1Pz\nUY9wcj7Vw8mBknukmvDNr73Yn+3F/tR81COcdAGHZrhnRR1eV5IktYFG1zkphJZVC3mSEMLaEMJt\nwP8FYgjhoXTBbteCW9hA9fiNYr7POdfvm839M91T7fpcH8+SWrdxIc83l++tZ39Ody3rfWp/zu1a\np/XnQp6z0e+5rdafLVmELcb4dIzxphjj+THGxem6lJtijJPNbttcdPI/lOmuZ/Efymz5w2xu17Le\np/bn3K51Wn8u5DkNJ9NrybN1FmA5wP79+5vdDgAmJycZHR3NxHPO9ftmc/9M91S7XqvHm6HWbVnI\n883le+vZn9Ndq/S4/bnw77U/K+vk99xa9GfJz87ls2r0AoQY49y/KTkJ+IcxxusqXDsOfL3KtR7g\nR8AVMcYH59HeBQkhfAb4ZqNfV5KkNnJljPG+er5APUZODlB9Tcmqknua4R+BK4FngDea1AZJklrR\ncuAckp+ldVWPcDIKrKxyrXDGzk/q8LozijG+BNQ17UmS1MYen+mGEMKKGONMu3anVY8FsQ9TvY7J\nBcBIHV6zZkII69JpK7W4EMI1IYQbQghfCyHcH0JY2+w2af7S/rymcJRGCOEDzW6TaieEMJBWDVcL\nCiH0hBCOp0s7Xg4hvBxC+P35Pl89Rk6+BXwlhLA2xvh02bUrgC/X4TUXLH2j25Z+2dPMtmjhQghf\nAW6JMb6afn0NMJL+f9lSu7oEIYSvAw/FGB9Iv/4USX+utD9bXwhhHXAbyUn2ak2RpP9eJjly5pmF\nPNl8R05WAqdXupAO5VwDfL308fSk4qdijH81z9esqxjjj9Pzg+5vdltUE5+i5P/RGONd6R8/15zm\naIFWMvUH14/Tz71NaItq7zKatxZRtfNKjPEnCw0mMIeRkxDCDSTTMj3AWuCcdPrjALC78BsNQIzx\ngRDCobRQ2hjJWpNVMcaPLLTB0iytAj5Acp5Twct4dEJLqnC+Vg/Jb2pOwba4dBRsN2Un2auzzeVU\n4p1zeeIY4yPAI3Nu0Ryl25O3lp6aXOGey0iSeSEozfnvo8aoVX/GGCvtGDsd+GHtWquZ1PHf503A\ntYVpOzVOLfs0nc55JcY4GUKoU4s1nRr/G70shHA+yS+CFwBfnu+0a0sXYUuniu4Cds1wz9bS37xC\nCJeGEB6KMX64Ac3ULNWzP9N/XKeRHHmgBqhHf6a/ZW8DdmV1irid1aFPLy2ZclWD1bg/DwEHStaF\njZJsgPmt+bStJcvXF1brkwzrvjTNfStI1pBMGS5MR3UKiyTVZA3qz68Bvf6mXX/17M8Y4wPpm2Rw\nV13j1KNPS6Zz1GD16M/0WJnS5R1Pl98zFy0ZTtJzdLam/yGm20u9FRirsjjnYeDaerRPc1Pv/gwh\nfA34XLPq63SaRvz7TIeUe9J1baqzWvdp+kOPCr8sOLfTAA38GXqIeS5ab+lpnVn4NNVXgD9N8uZ2\nmr9Nt4w592e6kPv+GOOjjWig5mRW/UnyS9RdwEBZeYKnAetiZMts+rQrvW99COGCkuvrgGtDCL87\n3foHNdSs33NDCK8A/6Xsl8BAMjozZy05cjIH51P9P+yBknvUGubUn4VaGKXBxKm8TJltf64j2Rre\nVXbP2mm+X80xmz7tjTHelf72/tZHeu1rBpNMmct77g8r3LuWZIRlztp95KSL6YesIF15rJYw6/5M\nV6BvBB5KF8NC8kNuXiledTGr/owxPhpC+Erpb2Rpn0bgxno2UHO20PfcakefqDnm0p/fomRaLoTw\nOZIpoXkd8tvu4WQ6hf/gqwDS0ubXkmyXiiGEh0jOCZr3Vig11Fv9mQ4b/xPJP5obSu6JwO82umGa\nlyn/PoHb0im6QmG9dSS/gT/T6IZp3sr7FEh2fpC890bgphDCOks9tIQp/RljvCs9LgSSf6cxxnhB\ntW+eSSeHkynSuWyHE9tAGiarnYytFpT2qT+w2lCjamKp/moZKtt9zYkkSWoxnRBOqs1vFh5/uVEN\nUU3Yn+3F/mw/9ml7aUp/tns4OUD14f1VJfeoNdif7cX+bD/2aXtpWn+2ezgZpfrq70IRIAtztQ77\ns73Yn+3HPm0vTevPdg8nD1O9jskFJHX/1Trsz/Zif7Yf+7S9NK0/2z2cfAve2iZc7grg641tjhbI\n/mwv9mf7sU/bS9P6sx3CyUqKtQ+miDEeAq6h7D9gesriU55qmkn2Z3uxP9uPfdpeMtmfIcbWK5iZ\nFmO6AOihWPXzxyQLc3aXnoyY3n8pSfGtMZJ5slUxxj9qaKNVlf3ZXuzP9mOftpdW6M+WDCeSJKl9\ntcO0jiRJaiOGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCmG\nE0mSlCmGE0mSlCmGE0mSlCmGE0mSlCn/H9FL7CDl9VcxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141409c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(x,y, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:26.830Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting models: ['curve', 'singSSA', 'doubSSA', 'singinhomobremss', 'singinhomobremssbreak', 'singinhomobremssbreakexp', 'doubhomobremss', 'doubSSAbreakexp']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:red>fitting with curve</text>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first guess: [6.5073699999999999, 1308.0, 0.7, -0.3]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -15240.420532\n",
      "         Iterations: 130\n",
      "         Function evaluations: 218\n"
     ]
    }
   ],
   "source": [
    "interactive = False\n",
    "model_list = [curve, singSSA, doubSSA, singinhomobremss, singinhomobremssbreak, singinhomobremssbreakexp, doubhomobremss, doubSSAbreakexp]\n",
    "model_names = [func.__name__ for func in model_list]\n",
    "print('fitting models: {0}'.format(model_names))\n",
    "models = pd.DataFrame(index = model_names, columns=['args','leastsquares', 'emcee', 'multinest'])\n",
    "freq_cont = np.linspace(np.min(x),np.max(y),1000)\n",
    "for func in model_list:\n",
    "    print_color(\"fitting with {0}\".format(func.__name__), 'red')\n",
    "    models.set_value(func.__name__,'args', get_argnames(func))\n",
    "    ndim = (func.__code__.co_argcount - 1)\n",
    "    n_params = ndim #oddly, this needs to be specified\n",
    "    prior_dict = make_prior_dictionary(func, x,y)\n",
    "    # your guess\n",
    "    guess = [value.guess for key, value in prior_dict.items()]\n",
    "    print('first guess: {0}'.format(guess))\n",
    "    # set least squares fit to be the initial parameter guess for fmin\n",
    "    leastsquares = pd.DataFrame(data=[[0]], columns=['initial_guess'], index=[0],dtype=object)\n",
    "    leastsquares['initial_guess'] = [guess]\n",
    "    \n",
    "    try:\n",
    "        popt, pcov = opt.curve_fit(func, x, y, p0 = guess, sigma = yerr)\n",
    "\n",
    "        redchisq_list = redchisq(y,func(x,*popt),yerr,ndim)\n",
    "\n",
    "        \n",
    "        leastsquares['popt'] = [popt]\n",
    "        leastsquares['pcov'] = [pcov]\n",
    "        leastsquares['redchisq'] = [redchisq_list]\n",
    "        \n",
    "    except:\n",
    "        leastsquares['popt'] = [[0,0]]\n",
    "        leastsquares['pcov'] = [[0,0]]\n",
    "        leastsquares['redchisq'] = [[0,0]]\n",
    "        \n",
    "    models.set_value(func.__name__,'leastsquares', leastsquares)\n",
    "    \n",
    "    # flip our likelihood function so that when we minimize nll, we are max'ing our likelihood?\n",
    "    nll = lambda *args: -lnlike(*args)\n",
    "\n",
    "    # minimize function with downhill simplex algorithm\n",
    "    # returns array of paramaters that minimizes the input function, value of function at that min, number of iterations, number of function calls\n",
    "    # warningflag 1 (max func evals reached) or 2 (max iter reached), solution at each iteration\n",
    "    result = opt.fmin(nll, popt, args=(ndim,n_params), full_output='true')\n",
    "\n",
    "    scale = 1e-3 # noise scale, should be less than 1 \n",
    "    pos = populate_walkers(ndim, scale, nwalkers, prior_dict, guess=result[0], set_to_random=True)\n",
    "    # initializing walkers randomly\n",
    "    #pos = np.random.rand(nwalkers, ndim)\n",
    "\n",
    "#     print('*lnprior1*', list(map(lambda p: emcee_lnprior(p, prior_dict), pos)))\n",
    "#     print('*lnlike*', list(map(lambda p: lnlike(p, ndim, n_params), pos)))\n",
    "#     print('*lnprob*', list(map(lambda p: emcee_lnprob(p, ndim, n_params, prior_dict), pos)))\n",
    "    \n",
    "\n",
    "    # for the prior\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, emcee_lnprob, args=(ndim, n_params, prior_dict))\n",
    "    sampler.run_mcmc(pos, nsteps) # This is the workhorse step.\n",
    "\n",
    "    fig = plt.figure(2,figsize=(10, 10))\n",
    "    fig.clf()\n",
    "    for j in range(ndim):\n",
    "        ax = fig.add_subplot(ndim,1,j+1)\n",
    "        ax.plot(np.array([sampler.chain[:,i,j] for i in range(nsteps)]),\"k\", alpha = 0.3)\n",
    "        ax.set_ylabel((make_plot_labels(func))[j], fontsize = 15)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "    plt.xlabel('Steps', fontsize = 15)\n",
    "    display(fig)\n",
    "\n",
    "\n",
    "    if interactive:\n",
    "        burnin = int(input('burnin?'))\n",
    "    fig.clf()\n",
    "\n",
    "\n",
    "    # To me it looks like the burn in period is well and truly over by n steps. So I will exclude those. \n",
    "    print( 'The burnin applied was {0}. Make sure the walkers have converged after that many steps.'.format(burnin))\n",
    "    samples = sampler.chain[:,burnin:,:].reshape((-1,ndim))\n",
    "    # Plotting the histograms of the fit.\n",
    "    trifig = corner.corner(samples, labels = make_plot_labels(func))\n",
    "    trifig.savefig(image_dir+'/{0}_{1}'.format(name,func.__name__))\n",
    "    plt.close()\n",
    "\n",
    "    # Finally to get the final uncertainties you do\n",
    "    uncertainties_mcmc = list(map(lambda v: (v[1], v[2]-v[1], v[1]-v[0]), zip(*np.percentile(samples,[16,50,84], axis = 0)))) # Uncertainites based on the 16th, 50th and 84th percentile.\n",
    "    emcee_fit = np.asarray([u[0] for u in uncertainties_mcmc])\n",
    "\n",
    "    flux_arr_store = np.zeros((200,1000))\n",
    "    lower_flux_arr, upper_flux_arr = np.zeros(1000), np.zeros(1000)\n",
    "\n",
    "    j=0\n",
    "    for sample in samples[np.random.randint(len(samples), size=200)]:\n",
    "        for i in range(1000):\n",
    "            flux_arr_store[j,i] = func(freq_cont[i], *sample)\n",
    "            lower_flux_arr[i], upper_flux_arr[i] = np.percentile(flux_arr_store[:,i],[16,84], axis = 0)\n",
    "        j = j+1\n",
    "\n",
    "    mc = pd.DataFrame(data=[[0]], columns=['nwalkers'], index=[0], dtype=object)\n",
    "    mc['nwalkers'] = nwalkers\n",
    "    mc['nsteps'] = nsteps\n",
    "    mc['burnin'] = burnin\n",
    "    mc['rand_seed'] = rand_seed\n",
    "    mc['uncertainties'] = [uncertainties_mcmc]\n",
    "    mc['lowerfluxarr'] = [lower_flux_arr]\n",
    "    mc['upperfluxarr'] = [upper_flux_arr]\n",
    "    mc['fit'] = [emcee_fit]\n",
    "\n",
    "    models.set_value(func.__name__,'emcee', mc)\n",
    "\n",
    "\n",
    "\n",
    "    # multinest\n",
    "    # number of dimensions our problem has\n",
    "    ndim = (func.__code__.co_argcount - 1)\n",
    "    n_params = ndim #oddly, this needs to be specified\n",
    "    print('emcee fit: {0}'.format(emcee_fit))\n",
    "\n",
    "    # sigma away from emcee's guess\n",
    "    sig = 3\n",
    "    pymultinest.run(lnlike,multinest_lnprior,n_params, resume = False, verbose = True,sampling_efficiency = 0.3)\n",
    "\n",
    "    # lets analyse the results\n",
    "    a = pymultinest.Analyzer(n_params = n_params) #retrieves the data that has been written to hard drive\n",
    "    s = a.get_stats()\n",
    "    values = s['marginals'] # gets the marginalized posterior probability distributions \n",
    "    mn_fit = [values[i]['median'] for i in np.arange(len(values))]\n",
    "    multinest = pd.DataFrame(data=[[0]], columns=['marginals'], index=[0], dtype=object)\n",
    "    multinest['fit'] = [mn_fit]\n",
    "    for key in s:\n",
    "        if isinstance(s[key], list):\n",
    "            pass\n",
    "        else:\n",
    "            multinest[key] = s[key]\n",
    "\n",
    "    marginals = pd.DataFrame.from_dict(s['marginals'], dtype=None)\n",
    "    modes = pd.DataFrame.from_dict(s['modes'], dtype=None)\n",
    "    multinest.set_value(0,'marginals', marginals)\n",
    "    multinest.set_value(0,'modes', modes)\n",
    "\n",
    "    models.set_value(func.__name__,'multinest', multinest)\n",
    "\n",
    "    print('summary for {0}'.format(func.__name__))\n",
    "    print(\" \"*20+'{0}'.format(func.__code__.co_varnames[:func.__code__.co_argcount][1:]))\n",
    "    print('leastsquares fit:{0}'.format(popt))\n",
    "    print('emcee fit: {0}'.format(emcee_fit))\n",
    "    print('multinest fit:{0}'.format(mn_fit))\n",
    "    print('diff bw emcee and multinest:')\n",
    "    print(np.subtract(emcee_fit,mn_fit))\n",
    "\n",
    "models.to_pickle(model_ev_dir + name + '.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-21T15:18:22.677468",
     "start_time": "2017-07-21T15:18:22.669557"
    },
    "collapsed": false
   },
   "source": [
    "## Evidence Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:26.903Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_delz(z2, models):\n",
    "    # Jefferys Scale\n",
    "    # delz >= 3 is strong evidence that M2 is favored over M1\n",
    "    # 1 < delz < 3 is moderate evidence\n",
    "    # 0 < delz < 1 is inconclusive\n",
    "    # delz = z2 - z1\n",
    "    z2_ev = models.loc[z2].multinest['nested sampling global log-evidence'].values[0]\n",
    "    z2_ev_err = models.loc[z2].multinest['nested sampling global log-evidence error'].values[0]\n",
    "    \n",
    "    for idx in models.index:\n",
    "        if z2 == idx:\n",
    "            continue\n",
    "        mn_ev = models.loc[idx].multinest['nested sampling global log-evidence'].values[0]\n",
    "        mn_ev_err = models.loc[idx].multinest['nested sampling global log-evidence error'].values[0]\n",
    "        del_z = z2_ev - mn_ev\n",
    "        del_z_err = z2_ev_err - mn_ev_err\n",
    "        string = '({0} - {1}): {2:.2f} +/- {3:.2f}'.format(z2, idx, del_z, del_z_err)\n",
    "        \n",
    "        if del_z >= 3:\n",
    "            print_color(string + '   *', color='red')\n",
    "        elif 1 < del_z < 3:\n",
    "            print_color(string, color='maroon')\n",
    "        elif 0 < del_z < 1:\n",
    "            print_color(string, color='black')\n",
    "        else:\n",
    "            print_color(string, color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:26.908Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out evidence\n",
    "mn_ev_arr = []\n",
    "for idx in models.index:\n",
    "    mn_evidence = models.loc[idx].multinest['nested sampling global log-evidence'].values[0]\n",
    "    mn_evidence_err = models.loc[idx].multinest['nested sampling global log-evidence error'].values[0]\n",
    "    mn_ev_arr.append(mn_evidence + np.abs(mn_evidence_err))\n",
    "    print('multinest evidence for {0}: {1:.2f} +/- {2:.2f}'.format(idx,mn_evidence,mn_evidence_err))\n",
    "best_model = [models.index[x] for x in np.argsort(mn_ev_arr)[::-1]]\n",
    "print('best to worst models: {0}'.format(best_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:26.927Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Jefferys Scale\n",
    "# delz = z2 - z1\n",
    "\n",
    "print_color('delz >= 3 is strong evidence that M2 is favored over M1', color = 'red')\n",
    "print_color('1 < delz < 3 is moderate evidence', color = 'maroon')\n",
    "print_color('0 < delz < 1 is inconclusive', color = 'black')\n",
    "\n",
    "for idx in models.index:\n",
    "    show_delz(idx, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:26.932Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save data frames\n",
    "sed_df.set_value(source_index, 'best_model', best_model)\n",
    "sed_df.to_pickle(model_ev_dir+'modeled_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latex Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:27.000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latex_dict = {'curve': 'General', 'singSSA': 'Single SSA', 'doubSSA': 'Double SSA', 'singinhomobremss':'Single Inhomogeneous FFA',\n",
    "              'singinhomobremssbreak':'Single Inhomogeneous FFA + break', 'singinhomobremssbreakexp':'Single Inhomogeneous FFA + exp. break',\n",
    "              'doubhomobremss':'Double Homogeneous FFA','doubSSAbreakexp':'Double SSA + exp. break'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:27.007Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate latex table of result\n",
    "tex_code = r'''\n",
    "\\begin{sidewaystable}\n",
    "\t\\renewcommand{\\arraystretch}{2}\n",
    "\t\\scriptsize\n",
    "\t\\centering\n",
    "\t\\caption{\\label{longtable} Best fit parameters and their associated uncertainties for the different absorption models. }\n",
    "        \\resizebox{\\linewidth}{!}{%\n",
    "\t\\begin{tabular}{lccccccccccccc}\n",
    "\t\\hline\n",
    "\t\\hline\n",
    "Models & $a_{1}$ (Jy) &  $a_{2}$ (Jy) & $\\alpha_{1}$ & $\\alpha_{2}$ & $\\beta_{1}$ & $\\beta_{2}$  & $\\nu_{\\mathrm{p},1}$ (GHz)  & $\\nu_{\\mathrm{p},2}$ (GHz)  & $p$ & $q$ & $\\nu_{\\mathrm{br}}$ (GHz) & $\\chi^{2}_{\\mathrm{red}}$ & $\\ln(Z)$ \\\\\n",
    "\t\t\\hline'''\n",
    "\n",
    "for idx in models.index.tolist():\n",
    "    args = list(models.loc[idx].args)\n",
    "    values = models.loc[idx].multinest['fit'].values[0]\n",
    "    errs =  models.loc[idx].multinest.marginals.values[0].sigma.values\n",
    "    print(idx,args, values)\n",
    "    toprint = '\\n {0} & '.format(latex_dict[idx])\n",
    "    for parameter in ['S_norm','S_norm2', 'alpha', 'alpha2', 'beta', 'beta2', 'peak_freq', 'peak_freq2', 'p', 'q', 'break_freq']:\n",
    "        if parameter not in args:\n",
    "            toprint += '$\\cdots$ & '\n",
    "        else:\n",
    "            toprint += '{0:.2f} '.format(values[args.index(parameter)])\n",
    "            #find_param_uncertainty(value)\n",
    "            toprint += '$\\pm$ {0:.2f} & '.format(errs[args.index(parameter)])\n",
    "    # reduced chi\n",
    "    red_chi = models.loc[idx].leastsquares.redchisq.values[0]\n",
    "    toprint += '{0:.2f} '.format(red_chi[0])\n",
    "    toprint += r'$\\pm$ {0:.2f} & '.format(red_chi[1])\n",
    "    \n",
    "    # lnz\n",
    "    mn_evidence = models.loc[idx].multinest['nested sampling global log-evidence'].values[0]\n",
    "    mn_evidence_err = models.loc[idx].multinest['nested sampling global log-evidence error'].values[0]\n",
    "    toprint += '{0:.2f} '.format(mn_evidence)\n",
    "    toprint += r'$\\pm$ {0:.2f} \\\\'.format(mn_evidence_err)\n",
    "    \n",
    "\n",
    "\n",
    "    tex_code += toprint\n",
    "\n",
    "\n",
    "tex_code += r'''\n",
    "        \\hline\n",
    "        \\end{tabular}}\n",
    "\\end{sidewaystable}\n",
    "'''\n",
    "\n",
    "#{0}  & {1:.2f} $\\pm$ {2:.2f} &  {3} &  {4} $\\pm$ {5}    & {6}  &  {7} & {8} & {9} $\\pm$ {10}   &  {11} & {12} & {13}  & {14} & {15} $\\pm${16} \\\\\n",
    "\n",
    "\n",
    "# \t Double Homogeneous FFA & 3.6 $\\pm$ 0.2 &  5.8 $\\pm$ 0.2 & $-1.27^{+0.05}_{-0.04}$  &  $-1.28$ $\\pm$ 0.03 & $\\cdots$\t& $\\cdots$  & 0.293 $\\pm$ 0.007  & 0.93 $\\pm$ 0.05  & $\\cdots$ & $\\cdots$ & 5.52 & $-422.4$ $\\pm$ 0.2 \\\\\n",
    "# \t Inhomogeneous FFA  & 12.0 $\\pm$  0.3 &   $\\cdots$ &  $-1.221$ $\\pm$ 0.008 & $\\cdots$  &$\\cdots$ &$\\cdots$ & 0.75 $\\pm$ 0.02 & $\\cdots$ & 0.24 $\\pm$ 0.04 & $\\cdots$ & 5.72& $-419.0$ $\\pm$ 0.6\\\\\n",
    "# \t Internal FFA & 8.8 $\\pm$ 0.1 &  $\\cdots$ & $-1.240$ $\\pm$ 0.008  &  $\\cdots$ & $\\cdots$& $\\cdots$ & 0.90 $\\pm$ 0.02 & $\\cdots$ & $\\cdots$ & $\\cdots$ & 7.13 & $-567.4$ $\\pm$ 0.2\\\\\n",
    "# \t   Single SSA & 13.4 $\\pm$ 0.2  & $\\cdots$ & $\\cdots$ &$\\cdots$ & 3.27 $\\pm$ 0.01 \t& $\\cdots$ & 0.575 $\\pm$ 0.008  & $\\cdots$   & $\\cdots$ & $\\cdots$ & 13.83& $-609.5$ $\\pm$ 0.1 \\\\\n",
    "# \tDouble SSA & 12.2 $\\pm$ 0.3 & 2.5 $\\pm$ 0.2 & $\\cdots$ & $\\cdots$ & 3.48 $\\pm$ 0.06 &  3.56$^{+0.08}_{-0.07}$ & 0.459 $\\pm$ 0.009  &  1.56 $\\pm$ 0.7 & $\\cdots$& $\\cdots$ &5.36 & $-408.5$ $\\pm$ 0.3\\\\\n",
    "# \t Single SSA + exp. break & 12.4 $\\pm$  0.2 \t& $\\cdots$ &$\\cdots$ &  $\\cdots$ & 2.61 $\\pm$ 0.03 & $\\cdots$  & 0.75 $\\pm$ 0.02  & $\\cdots$ & 13.7 $\\pm$ 0.7 & $\\cdots$ & 2.39 & $-336.6$ $\\pm$ 0.2\\\\\n",
    "# \t Double SSA + exp. break & 8.3$^{+0.6}_{-0.7}$ & 6.1$^{+0.7}_{-0.6}$  & $\\cdots$  &  $\\cdots$ & 3.3$^{+0.3}_{-0.2}$ &  2.55$^{+0.06}_{-0.08}$ & 0.34$^{+0.07}_{-0.08}$   &  0.73$^{+0.04}_{-0.05}$ & $\\cdots$ & 12 $\\pm$ 2 & 1.09 & $-305.8$ $\\pm$ 0.3 \\\\\n",
    "# \t Inhomogeneous FFA + exp. break & 12.9 $\\pm$  0.3\t& $\\cdots$ & $-0.93$ $\\pm$ 0.02  & $\\cdots$ &$\\cdots$ & $\\cdots$& 0.55 $\\pm$ 0.02  & $\\cdots$ & 0.37$^{+0.07}_{-0.06}$ & 19 $\\pm$ 1 & 0.80 & $-304.1$ $\\pm$ 0.1\\\\\n",
    "\n",
    "print(tex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SED Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:27.079Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# SED plotting\n",
    "n = 100\n",
    "plotx, ploty, plotyerr = atca_filter(n, x, y, yerr)\n",
    "try:\n",
    "    split = re.split('([0-9]+)',name) \n",
    "    plotname = split[0].upper() + \" B\"+\"\".join(split[1:])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model_labels = [latex_dict[model.__name__] for model in model_list]\n",
    "\n",
    "print('least squares')\n",
    "# least squares fit plot\n",
    "fit_list = [models.loc[model.__name__].leastsquares.popt[0] for model in model_list]\n",
    "\n",
    "plot = seds_plot_func.sed(model_list,model_labels,fit_list,plotx,\n",
    "           ploty,plotyerr, plotname, \n",
    "           freq_labels = True, savefig = False, resid=True)\n",
    "\n",
    "plot.savefig(image_dir+'/{0}_{1}.png'.format(name,'leastsquares'), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "print('emcee')\n",
    "# emcee fit plot\n",
    "fit_list = [models.loc[model.__name__].emcee.fit[0] for model in model_list]\n",
    "\n",
    "plot = seds_plot_func.sed(model_list,model_labels,fit_list,plotx,\n",
    "               ploty,plotyerr, plotname, \n",
    "               freq_labels = True, savefig = False, resid=True)\n",
    "\n",
    "plot.savefig(image_dir+'/{0}_{1}.png'.format(name,'emcee'), bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "print('multinest')\n",
    "# multinest fit plotting\n",
    "fit_list = [models.loc[model.__name__].multinest.fit[0] for model in model_list]\n",
    "\n",
    "plot = seds_plot_func.sed(model_list,model_labels,fit_list,plotx,\n",
    "                   ploty,plotyerr, plotname, \n",
    "                   freq_labels = True, savefig = False, resid=True)\n",
    "plot.savefig(image_dir+'/{0}_{1}.png'.format(name,'multinest'), bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:27.086Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out evidence\n",
    "mn_ev_arr = []\n",
    "for idx in models.index:\n",
    "    mn_evidence = models.loc[idx].multinest['nested sampling global log-evidence'].values[0]\n",
    "    mn_evidence_err = models.loc[idx].multinest['nested sampling global log-evidence error'].values[0]\n",
    "    mn_ev_arr.append(mn_evidence + np.abs(mn_evidence_err))\n",
    "    print('multinest evidence for {0}: {1:.2f} +/- {2:.2f}'.format(idx,mn_evidence,mn_evidence_err))\n",
    "best_model = [models.index[x] for x in np.argsort(mn_ev_arr)[::-1]]\n",
    "print('best to worst models: {0}'.format(best_model))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-07-31T14:14:27.093Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indx = [i for i,x in enumerate(x) if (x > 1000 and x < 300)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
